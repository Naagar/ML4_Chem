{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial 7 - Introduction to PyTorch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc61923b4b864561ab4b5e8e2869e86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be769e657fcd4ce7bf137d30cb6c9671",
              "IPY_MODEL_48a3d77a6aff49009e7730d8d82f3ddd",
              "IPY_MODEL_49c05dc02ca743299e0ff35b6665fd85"
            ],
            "layout": "IPY_MODEL_228d34c2f74c49d4ac5c8cc70bf5695a"
          }
        },
        "be769e657fcd4ce7bf137d30cb6c9671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_213467c542d44f57a60b3c00ca3e4091",
            "placeholder": "​",
            "style": "IPY_MODEL_0ea4ba7bf47845598cfd3f39bfdd2530",
            "value": ""
          }
        },
        "48a3d77a6aff49009e7730d8d82f3ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3560729dc9a743919bac7cd23a48366b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f8f2db5bb8a4cb99d4300d3ecfce60c",
            "value": 1
          }
        },
        "49c05dc02ca743299e0ff35b6665fd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1c13ae608e454fa7d17001314164aa",
            "placeholder": "​",
            "style": "IPY_MODEL_2a2763b2871e42d7b1bfd612480eb9f5",
            "value": " 1128/? [00:01&lt;00:00, 1018.06it/s]"
          }
        },
        "228d34c2f74c49d4ac5c8cc70bf5695a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213467c542d44f57a60b3c00ca3e4091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ea4ba7bf47845598cfd3f39bfdd2530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3560729dc9a743919bac7cd23a48366b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6f8f2db5bb8a4cb99d4300d3ecfce60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c1c13ae608e454fa7d17001314164aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a2763b2871e42d7b1bfd612480eb9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 7 - Introduction to PyTorch"
      ],
      "metadata": {
        "id": "QRNyh0BBQgX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors are data structures that are similar to arrays and matrices. Tensors are similar to NumPy arrays and they can run on GPUs or other specialized hardware to accelerate computing. PyTorch is a machine learning framework that allows us to create, train, and test models. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters."
      ],
      "metadata": {
        "id": "nz2Ydqy1Q1Q7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF3A6eKrQG2F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        "### Creating a tensor"
      ],
      "metadata": {
        "id": "R70xtIwuRgrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1,2], [3,4]]\n",
        "x_data = torch.tensor(data)\n",
        "\n",
        "print(x_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRuIoh76RYzG",
        "outputId": "eef13068-1df1-49fa-abb5-f13b55999479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np_tensor = torch.from_numpy(np_array)\n",
        "\n",
        "print(x_np_tensor, type(x_np_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaHeltQhRv-z",
        "outputId": "745538fa-fc29-4978-e400-9ff9c0a943d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]]) <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensors of a specific shape\n",
        "\n",
        "shape = (2, 3,)\n",
        "\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor of shape {shape}: \\n{rand_tensor}\\n\")\n",
        "print(f\"Ones Tensor of shape {shape}: \\n{ones_tensor}\\n\")\n",
        "print(f\"Zero Tensor of shape {shape}: \\n{zeros_tensor}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIMMI9J0SRnF",
        "outputId": "5d6787cc-2f11-468b-82ff-01485e3268f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor of shape (2, 3): \n",
            "tensor([[0.6786, 0.0137, 0.8147],\n",
            "        [0.5991, 0.9891, 0.7848]])\n",
            "\n",
            "Ones Tensor of shape (2, 3): \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n",
            "Zero Tensor of shape (2, 3): \n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.rand_like(x_np_tensor, dtype=torch.float)\n",
        "print(x_ones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvlKY4Z8Sw-Z",
        "outputId": "35b95812-8361-4006-9c90-514ed8dc0c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1960, 0.4169],\n",
            "        [0.3002, 0.6913]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Attributes and Operations"
      ],
      "metadata": {
        "id": "nzVUvRrCTa9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_np_tensor.shape)\n",
        "print(x_np_tensor.size())\n",
        "print(x_np_tensor.dtype)\n",
        "print(x_np_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dRXveo2S77n",
        "outputId": "d6d436c4-6e95-4294-bfa0-b9e539f6bd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.Size([2, 2])\n",
            "torch.int64\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_np_tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBN_3MLwTgHU",
        "outputId": "332a6ee1-24cb-40f6-f207-bec3e53bd195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Edit -> Notebook Settings -> Hardware accelerator -> GPU"
      ],
      "metadata": {
        "id": "NmTRtnShUGJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  x_np_tensor = x_np_tensor.to('cuda')"
      ],
      "metadata": {
        "id": "KfkfJlzJT630"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_np_tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsnt8-EnUg9C",
        "outputId": "120954fc-ae49-4774-89f4-5f2840c63772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_np_tensor.view(1,4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acYJeHWNUxx0",
        "outputId": "d8a47c68-69fe-4e92-9356-e57a29662a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 4]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4,4)\n",
        "tensor[:,2] = 0"
      ],
      "metadata": {
        "id": "baZHnEGwVb9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGA8wJKzVtJg",
        "outputId": "39f840fc-1810-4e1e-c735-2da4f4100916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor cat and stack operations\n",
        "\n",
        "cat_tensor = torch.cat([tensor, tensor], dim=1)\n",
        "print(cat_tensor, cat_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsVpyC6LVw0O",
        "outputId": "dcc27f2e-01ce-4593-96bb-fc4683e6a259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 0., 1., 1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1., 1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1., 1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1., 1., 1., 0., 1.]]) torch.Size([4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stack_tensor = torch.stack([tensor, tensor], dim=1)\n",
        "print(stack_tensor, stack_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgDQ3OvdVxg8",
        "outputId": "ac76d37f-fb39-4043-bbb8-e4376c02f0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 1., 0., 1.],\n",
            "         [1., 1., 0., 1.]],\n",
            "\n",
            "        [[1., 1., 0., 1.],\n",
            "         [1., 1., 0., 1.]],\n",
            "\n",
            "        [[1., 1., 0., 1.],\n",
            "         [1., 1., 0., 1.]],\n",
            "\n",
            "        [[1., 1., 0., 1.],\n",
            "         [1., 1., 0., 1.]]]) torch.Size([4, 2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor)\n",
        "\n",
        "mult_tensor = tensor.mul(tensor)\n",
        "print(mult_tensor)\n",
        "\n",
        "mult_tensor = tensor*tensor\n",
        "print(mult_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21E6uvLcWt8M",
        "outputId": "9082830e-a5d5-45d9-eb7b-3d7085affd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.]])\n",
            "tensor([[1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.]])\n",
            "tensor([[1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat_mul_tensor = tensor.matmul(tensor)\n",
        "print(mat_mul_tensor)\n",
        "\n",
        "mat_mul_tensor = tensor @ tensor\n",
        "print(mat_mul_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkKBgqOeZHto",
        "outputId": "fda1d5b6-d276-4a60-c006-39f7943b6b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.]])\n",
            "tensor([[3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.],\n",
            "        [3., 3., 0., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat_mul_tensor = tensor.matmul(tensor.T)\n",
        "print(mat_mul_tensor)\n",
        "\n",
        "mat_mul_tensor = tensor @ tensor.t()\n",
        "print(mat_mul_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJtzJ3Z1ZYUV",
        "outputId": "2d048923-47f6-4cf1-9c58-6e1bf2f6fa24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n",
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxNquj0iZnRS",
        "outputId": "906f664d-a1e6-4f05-be0c-b4332d34fd42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6., 6., 5., 6.],\n",
            "        [6., 6., 5., 6.],\n",
            "        [6., 6., 5., 6.],\n",
            "        [6., 6., 5., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HKPzcpbgaNaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autograd for tensors"
      ],
      "metadata": {
        "id": "Q2GlXKuHaN1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autograd is now a core torch package for automatic differentiation. It uses a tape based system for automatic differentiation. In autograd, if any input Tensor of an operation has requires_grad=True, the computation will be tracked. In the forward phase, the autograd tape will remember all the operations it executed, and in the backward phase, it will replay the operations."
      ],
      "metadata": {
        "id": "prnGbrXnaMk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvB7hGYYZ1ci",
        "outputId": "79009050-4003-445f-d234-1f19375ad0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHgQHTaRak4R",
        "outputId": "26f29b30-7c99-4ac3-914f-c53b891aa6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x ** 2\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny_DgGinaput",
        "outputId": "f37078fa-4b5b-4a1f-f5f0-3cf0a98f4970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y = x*8\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXmmHAO6atRP",
        "outputId": "4f0110c9-9506-42bc-9979-51af25f7c2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[8., 8.],\n",
            "        [8., 8.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing a Simple Neural Network with PyTorch"
      ],
      "metadata": {
        "id": "FlfCwbtmbbnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "GAJGxaobbG2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        n_features = 512\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(n_features, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 1),\n",
        "    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "device = \"cpu\"\n",
        "\n",
        "print(f\"Using {device} device\")\n",
        "model = NeuralNetwork().to(device)\n",
        "\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fSBOdxqbf4e",
        "outputId": "9e7fc24e-b704-4d8e-e463-45ce4a0355e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 512\n",
        "\n",
        "X = torch.rand(10, n_features, device=device)\n",
        "\n",
        "predictions = model(X)\n",
        "print(f\"Predicted class: {predictions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS_QVBDKcviF",
        "outputId": "750443b4-ddab-4c2e-e2f7-450a034948cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([[-0.0261],\n",
            "        [-0.0120],\n",
            "        [ 0.0037],\n",
            "        [-0.0177],\n",
            "        [-0.0342],\n",
            "        [-0.0096],\n",
            "        [ 0.0257],\n",
            "        [-0.0285],\n",
            "        [-0.0097],\n",
            "        [ 0.0088]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.rand(5, n_features, device=device)\n",
        "print(input_tensor.size())\n",
        "\n",
        "layer1 = nn.Linear(in_features=n_features, out_features=256)\n",
        "layer1 = layer1.to(device)\n",
        "\n",
        "hidden1 = layer1(input_tensor)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDlbFvGAdNOs",
        "outputId": "d4c1d388-3d20-42f4-dbeb-c8baf5702e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 512])\n",
            "torch.Size([5, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Activation function\n",
        "\n",
        "Non-linear activations are what create the complex mappings between the model’s inputs and outputs. They are applied after linear transformations to introduce nonlinearity, helping neural networks learn a wide variety of phenomena.\n",
        "\n",
        "\n",
        "We Use the ReLU activation function here. \n"
      ],
      "metadata": {
        "id": "LlOXLrRmefnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHeaLGSCdpsN",
        "outputId": "f8c0c1bb-ee3d-45a0-ea46-04b4f52bb835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.1003,  0.3482,  0.0528,  ..., -0.1302, -0.0600, -0.2550],\n",
            "        [-0.2661,  0.4191,  0.1047,  ..., -0.1795, -0.1268, -0.3053],\n",
            "        [-0.0054,  0.5258,  0.1014,  ..., -0.0630, -0.0058, -0.5310],\n",
            "        [ 0.1295,  0.3272, -0.0006,  ..., -0.2915, -0.0753, -0.2488],\n",
            "        [ 0.1131,  0.2473,  0.1776,  ..., -0.1378, -0.1342, -0.4045]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.1003, 0.3482, 0.0528,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.4191, 0.1047,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.5258, 0.1014,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.1295, 0.3272, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.1131, 0.2473, 0.1776,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 1)\n",
        ")\n",
        "seq_modules = seq_modules.to(device)\n",
        "\n",
        "input_tensor = torch.rand(10,n_features, device=device)\n",
        "\n",
        "logits = seq_modules(input_tensor)\n",
        "print(logits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jln5msSleJfc",
        "outputId": "b95a9839-e7b2-4b85-826e-deff4a6e8413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2164],\n",
            "        [-0.1073],\n",
            "        [-0.1362],\n",
            "        [-0.2694],\n",
            "        [-0.2072],\n",
            "        [-0.3088],\n",
            "        [-0.1843],\n",
            "        [-0.2047],\n",
            "        [-0.2641],\n",
            "        [-0.2594]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Last layer for prediction\n",
        "\n",
        "Since this is a regression task, no activation function is required for last layer.\n",
        "\n",
        "In a classification task, the last linear layer of the neural network returns logits - raw values in [-infty, infty]. The are passed to the nn.Softmax module and the logits are scaled to values [0, 1] representing the model’s predicted probabilities for each class. dim parameter indicates the dimension along which the values must sum to 1.\n"
      ],
      "metadata": {
        "id": "h9rtcpz5fRsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Neural Network hyperparameters\n",
        "\n",
        "Hyperparameters are adjustable parameters that let you control the model optimization process. Different hyperparameter values can impact model training and convergence rates \n",
        "\n",
        "We define the following hyperparameters for training:\n",
        "- Number of Epochs - the number times to iterate over the dataset\n",
        "- Batch Size - the number of data samples propagated through the network before the parameters are updated\n",
        "- Learning Rate - how much to update models parameters at each batch/epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training.\n"
      ],
      "metadata": {
        "id": "i1JpfR6Sf6vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "b_MrDNYefFM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss function\n",
        "\n",
        "When presented with some training data, our untrained network is likely not to give the correct answer. Loss function measures the degree of dissimilarity of obtained result to the target value, and it is the loss function that we want to minimize during training. To calculate the loss we make a prediction using the inputs of our given data sample and compare it against the true data label value.\n",
        "\n",
        "Common loss functions include nn.MSELoss (Mean Square Error) for regression tasks, and nn.NLLLoss (Negative Log Likelihood) for classification. nn.CrossEntropyLoss combines nn.LogSoftmax and nn.NLLLoss.\n",
        "\n"
      ],
      "metadata": {
        "id": "ushqTMjMgK1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the loss function\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "UTx3wyGwfqyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizer\n",
        "\n",
        "Optimization is the process of adjusting model parameters to reduce model error in each training step. Optimization algorithms define how this process is performed (in this example we use Stochastic Gradient Descent). All optimization logic is encapsulated in the optimizer object. Here, we use the SGD optimizer; additionally, there are many different optimizers available in PyTorch such as ADAM and RMSProp, that work better for different kinds of models and data.\n",
        "\n",
        "We initialize the optimizer by registering the model’s parameters that need to be trained, and passing in the learning rate hyperparameter.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CGMj5T5MgVPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "JYcXbd-FgRhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inside the training loop, optimization happens in three steps:\n",
        "\n",
        "- Call optimizer.zero_grad() to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
        "\n",
        "- Backpropagate the prediction loss with a call to loss.backward(). PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
        "\n",
        "- Once we have our gradients, we call optimizer.step() to adjust the parameters by the gradients collected in the backward pass.\n"
      ],
      "metadata": {
        "id": "_q95A3hlhPvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(X_train, Y_train, loss_fn, optimizer, device):\n",
        "    size = len(X_train)\n",
        "    batch_size = 32\n",
        "    n_batches = int(size/batch_size)\n",
        "    epochs = 50\n",
        "    for epoch_id in range(epochs):\n",
        "      running_loss = []\n",
        "      for batch_id in range(n_batches):\n",
        "          X_batch = X_train[batch_id*batch_size: (batch_id+1)*batch_size]\n",
        "          Y_batch = Y_train[batch_id*batch_size: (batch_id+1)*batch_size]\n",
        "          X_batch = torch.FloatTensor(X_batch, device=device)\n",
        "          Y_batch = torch.FloatTensor(Y_batch, device=device)\n",
        "\n",
        "          # Compute prediction and loss\n",
        "          pred = model(X_batch)\n",
        "          loss = loss_fn(pred.squeeze(-1), Y_batch)\n",
        "          running_loss.append(loss.item())\n",
        "          # Backpropagation\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          loss, current = loss.item(), batch_id * len(X)\n",
        "      print(f\" Epoch: {epoch_id} loss: {np.mean(running_loss):>7f}\")\n"
      ],
      "metadata": {
        "id": "YlmFHSZlhNEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **RDKit**"
      ],
      "metadata": {
        "id": "Zqo0AgUUhsQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-py37_4.8.3-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c rdkit rdkit\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSyFH5g2hmip",
        "outputId": "6b23061c-cdf6-4a91-84ce-74d16ad7d1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-30 12:58:00--  https://repo.continuum.io/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh [following]\n",
            "--2022-04-30 12:58:00--  https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \n",
            "The environment is inconsistent, please check the package plan carefully\n",
            "The following packages are causing the inconsistency:\n",
            "\n",
            "  - defaults/noarch::python-dateutil==2.8.2=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::pysocks==1.7.1=py37_0\n",
            "  - defaults/linux-64::glib==2.69.1=h4ff587b_1\n",
            "  - defaults/linux-64::numexpr==2.8.1=py37h6abb31d_0\n",
            "  - defaults/linux-64::mkl_random==1.2.2=py37h51133e4_0\n",
            "  - defaults/linux-64::cairo==1.16.0=hf32fb01_1\n",
            "  - defaults/linux-64::requests==2.23.0=py37_0\n",
            "  - rdkit/linux-64::rdkit==2020.09.1.0=py37hd50e099_1\n",
            "  - defaults/linux-64::ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "  - defaults/linux-64::readline==8.0=h7b6447c_0\n",
            "  - defaults/linux-64::py-boost==1.73.0=py37ha9443f7_11\n",
            "  - defaults/linux-64::fontconfig==2.13.1=h6c09931_0\n",
            "  - defaults/linux-64::six==1.14.0=py37_0\n",
            "  - defaults/linux-64::pyopenssl==19.1.0=py37_0\n",
            "  - defaults/linux-64::pixman==0.40.0=h7f8727e_1\n",
            "  - defaults/linux-64::cffi==1.14.0=py37he30daa8_1\n",
            "  - defaults/linux-64::cryptography==2.9.2=py37h1ba5d50_0\n",
            "  - defaults/linux-64::mkl-service==2.4.0=py37h7f8727e_0\n",
            "  - defaults/linux-64::libtiff==4.2.0=h85742a9_0\n",
            "  - defaults/linux-64::giflib==5.2.1=h7b6447c_0\n",
            "  - defaults/noarch::pycparser==2.20=py_0\n",
            "  - defaults/linux-64::tk==8.6.8=hbc83047_0\n",
            "  - defaults/linux-64::libffi==3.3=he6710b0_1\n",
            "  - defaults/linux-64::pandas==1.3.4=py37h8c16a72_0\n",
            "  - defaults/linux-64::libboost==1.73.0=h3ff78a5_11\n",
            "  - defaults/linux-64::bottleneck==1.3.4=py37hce1f21e_0\n",
            "  - defaults/linux-64::freetype==2.11.0=h70c0345_0\n",
            "  - defaults/noarch::tqdm==4.46.0=py_0\n",
            "  - defaults/linux-64::setuptools==46.4.0=py37_0\n",
            "  - defaults/noarch::pytz==2021.3=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::certifi==2021.10.8=py37h06a4308_2\n",
            "  - defaults/linux-64::conda-package-handling==1.6.1=py37h7b6447c_0\n",
            "  - defaults/noarch::packaging==21.3=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::lz4-c==1.9.3=h295c915_1\n",
            "  - defaults/linux-64::jpeg==9e=h7f8727e_0\n",
            "  - defaults/linux-64::yaml==0.1.7=had09818_2\n",
            "  - defaults/linux-64::pycosat==0.6.3=py37h7b6447c_0\n",
            "  - defaults/linux-64::openssl==1.1.1n=h7f8727e_0\n",
            "  - defaults/linux-64::numpy-base==1.21.5=py37hf524024_1\n",
            "  - defaults/linux-64::zlib==1.2.11=h7b6447c_3\n",
            "  - defaults/linux-64::libxml2==2.9.12=h03d6c58_0\n",
            "  - defaults/linux-64::python==3.7.7=hcff3b4d_5\n",
            "  - defaults/linux-64::numpy==1.21.5=py37he7a7128_1\n",
            "  - defaults/linux-64::mkl_fft==1.3.1=py37hd3c417c_0\n",
            "  - defaults/linux-64::libxcb==1.14=h7b6447c_0\n",
            "  - defaults/linux-64::pillow==9.0.1=py37h22f2fdc_0\n",
            "  - defaults/linux-64::wheel==0.34.2=py37_0\n",
            "  - defaults/linux-64::lcms2==2.12=h3be6417_0\n",
            "  - defaults/noarch::idna==2.9=py_1\n",
            "  - defaults/linux-64::conda==4.12.0=py37h06a4308_0\n",
            "  - defaults/linux-64::bzip2==1.0.8=h7b6447c_0\n",
            "  - defaults/linux-64::icu==58.2=he6710b0_3\n",
            "  - defaults/linux-64::libuuid==1.0.3=h7f8727e_2\n",
            "  - defaults/linux-64::sqlite==3.31.1=h62c20be_1\n",
            "  - defaults/linux-64::libwebp-base==1.2.2=h7f8727e_0\n",
            "  - defaults/linux-64::zstd==1.4.9=haebb681_0\n",
            "  - defaults/noarch::pyparsing==3.0.4=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::xz==5.2.5=h7b6447c_0\n",
            "  - defaults/linux-64::pip==20.0.2=py37_3\n",
            "  - defaults/linux-64::chardet==3.0.4=py37_1003\n",
            "  - defaults/linux-64::libgcc-ng==9.3.0=h5101ec6_17\n",
            "  - defaults/linux-64::ncurses==6.2=he6710b0_1\n",
            "  - defaults/linux-64::libedit==3.1.20181209=hc058e9b_0\n",
            "  - defaults/linux-64::libwebp==1.2.2=h55f646e_0\n",
            "  - defaults/linux-64::libpng==1.6.37=hbc83047_0\n",
            "  - defaults/linux-64::urllib3==1.25.8=py37_0\n",
            "  - defaults/linux-64::pcre==8.45=h295c915_0\n",
            "\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2020.4.5.1=py37_0\n",
            "    - cffi==1.14.0=py37he30daa8_1\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.1=py37h7b6447c_0\n",
            "    - conda==4.8.3=py37_0\n",
            "    - cryptography==2.9.2=py37h1ba5d50_0\n",
            "    - idna==2.9=py_1\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.3=he6710b0_1\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_1\n",
            "    - openssl==1.1.1g=h7b6447c_0\n",
            "    - pip==20.0.2=py37_3\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.20=py_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.7=hcff3b4d_5\n",
            "    - readline==8.0=h7b6447c_0\n",
            "    - requests==2.23.0=py37_0\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==46.4.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h62c20be_1\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.46.0=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  ca-certificates                      2022.3.29-h06a4308_1 --> 2020.1.1-0\n",
            "\n",
            "\n",
            "Preparing transaction: - \b\bdone\n",
            "Executing transaction: | \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m31.592s\n",
            "user\t0m21.450s\n",
            "sys\t0m8.100s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                                2020.1.1-0 --> 2022.3.29-h06a4308_1\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m5.210s\n",
            "user\t0m3.880s\n",
            "sys\t0m0.539s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rdkit\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n"
      ],
      "metadata": {
        "id": "lfzH1F3jhvSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./esol.csv')\n",
        "df = df[['measured log solubility in mols per litre','smiles']]\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for idx, row in tqdm(df.iterrows()):\n",
        "  smile = row['smiles']\n",
        "  sol = row['measured log solubility in mols per litre']\n",
        "\n",
        "  fingerprint = np.asarray(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smile),2,nBits=512))\n",
        "\n",
        "  X.append(fingerprint)\n",
        "  Y.append(sol)\n",
        "\n",
        "X = np.vstack(X)\n",
        "Y =  np.hstack(Y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "X_valid, X_test, Y_valid, Y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=42)\n",
        "print(X_train.shape,X_valid.shape,X_test.shape)\n",
        "print(Y_train.shape,Y_valid.shape,Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "bc61923b4b864561ab4b5e8e2869e86f",
            "be769e657fcd4ce7bf137d30cb6c9671",
            "48a3d77a6aff49009e7730d8d82f3ddd",
            "49c05dc02ca743299e0ff35b6665fd85",
            "228d34c2f74c49d4ac5c8cc70bf5695a",
            "213467c542d44f57a60b3c00ca3e4091",
            "0ea4ba7bf47845598cfd3f39bfdd2530",
            "3560729dc9a743919bac7cd23a48366b",
            "6f8f2db5bb8a4cb99d4300d3ecfce60c",
            "3c1c13ae608e454fa7d17001314164aa",
            "2a2763b2871e42d7b1bfd612480eb9f5"
          ]
        },
        "id": "dkJtQs_8h9vm",
        "outputId": "5c26abbe-a59d-491a-8e25-1d1d1d644f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc61923b4b864561ab4b5e8e2869e86f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(902, 512) (113, 512) (113, 512)\n",
            "(902,) (113,) (113,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loop(X_train, Y_train, loss_fn, optimizer, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4lqrt_iibHI",
        "outputId": "af3c4315-fbad-448a-b9c8-b349c79b1b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch: 0 loss: 1.880917\n",
            " Epoch: 1 loss: 1.855083\n",
            " Epoch: 2 loss: 1.830060\n",
            " Epoch: 3 loss: 1.805774\n",
            " Epoch: 4 loss: 1.782171\n",
            " Epoch: 5 loss: 1.759254\n",
            " Epoch: 6 loss: 1.736969\n",
            " Epoch: 7 loss: 1.715303\n",
            " Epoch: 8 loss: 1.694268\n",
            " Epoch: 9 loss: 1.673843\n",
            " Epoch: 10 loss: 1.653983\n",
            " Epoch: 11 loss: 1.634666\n",
            " Epoch: 12 loss: 1.615820\n",
            " Epoch: 13 loss: 1.597451\n",
            " Epoch: 14 loss: 1.579554\n",
            " Epoch: 15 loss: 1.562102\n",
            " Epoch: 16 loss: 1.545095\n",
            " Epoch: 17 loss: 1.528490\n",
            " Epoch: 18 loss: 1.512261\n",
            " Epoch: 19 loss: 1.496395\n",
            " Epoch: 20 loss: 1.480907\n",
            " Epoch: 21 loss: 1.465788\n",
            " Epoch: 22 loss: 1.451034\n",
            " Epoch: 23 loss: 1.436632\n",
            " Epoch: 24 loss: 1.422513\n",
            " Epoch: 25 loss: 1.408702\n",
            " Epoch: 26 loss: 1.395215\n",
            " Epoch: 27 loss: 1.382033\n",
            " Epoch: 28 loss: 1.369112\n",
            " Epoch: 29 loss: 1.356473\n",
            " Epoch: 30 loss: 1.344093\n",
            " Epoch: 31 loss: 1.331942\n",
            " Epoch: 32 loss: 1.320039\n",
            " Epoch: 33 loss: 1.308328\n",
            " Epoch: 34 loss: 1.296865\n",
            " Epoch: 35 loss: 1.285594\n",
            " Epoch: 36 loss: 1.274545\n",
            " Epoch: 37 loss: 1.263656\n",
            " Epoch: 38 loss: 1.252987\n",
            " Epoch: 39 loss: 1.242520\n",
            " Epoch: 40 loss: 1.232229\n",
            " Epoch: 41 loss: 1.222108\n",
            " Epoch: 42 loss: 1.212197\n",
            " Epoch: 43 loss: 1.202409\n",
            " Epoch: 44 loss: 1.192798\n",
            " Epoch: 45 loss: 1.183322\n",
            " Epoch: 46 loss: 1.173994\n",
            " Epoch: 47 loss: 1.164817\n",
            " Epoch: 48 loss: 1.155776\n",
            " Epoch: 49 loss: 1.146883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(X_test, Y_test, loss_fn):\n",
        "    size = len(X_test)\n",
        "    batch_size = 32\n",
        "    n_batches = int(size/batch_size)\n",
        "    running_loss = []\n",
        "    model.eval()\n",
        "    for batch_id in range(n_batches):\n",
        "        X_batch = X_test[batch_id*batch_size: (batch_id+1)*batch_size]\n",
        "        Y_batch = Y_test[batch_id*batch_size: (batch_id+1)*batch_size]\n",
        "        X_batch = torch.FloatTensor(X_batch)\n",
        "        Y_batch = torch.FloatTensor(Y_batch)\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X_batch)\n",
        "        loss = loss_fn(pred.squeeze(-1), Y_batch)\n",
        "        running_loss.append(loss.item())\n",
        "\n",
        "        loss, current = loss.item(), batch_id * len(X)\n",
        "\n",
        "        \n",
        "    print(f\" MSE: {np.mean(running_loss):>7f}\")\n"
      ],
      "metadata": {
        "id": "2RUjL22viqaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(X_test, Y_test, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_BtJNTtjNHl",
        "outputId": "2220ee06-b7bd-44f3-9f46-762b01f23b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " MSE: 2.027718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment: Toxicity classification\n",
        "\n",
        "\n",
        "You are given a dataset of SMILES and whether they are toxic or not. \n",
        "Task is to create a neural network model for predicting whether a given molecule is toxic or not. \n",
        "\n"
      ],
      "metadata": {
        "id": "xhqbxAV2juK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        n_features = 512\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(n_features, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 1),\n",
        "    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIuwuzbgjajD",
        "outputId": "545fb656-e077-4c9a-c9a6-b70697a0b3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bxbpYB99jzIj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}