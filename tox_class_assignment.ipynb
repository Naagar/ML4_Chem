{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tox_class_assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bf6ca46c5344e0db33b08f6ef7c1126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f907e213c234ec88f5445893f24a765",
              "IPY_MODEL_80d27f1cf9194563861a1a519d76c53a",
              "IPY_MODEL_0eae901446ee439491323fccff027cfb"
            ],
            "layout": "IPY_MODEL_8b129c022e674b5baa5450dfe9b98e32"
          }
        },
        "7f907e213c234ec88f5445893f24a765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85dceb627f854303972077e5e2720e47",
            "placeholder": "​",
            "style": "IPY_MODEL_7eda3e2fc4a3474fabe7dd1736d9f207",
            "value": ""
          }
        },
        "80d27f1cf9194563861a1a519d76c53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca040b13f16944b1a391be71866de055",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6f621d682434766864026378b3ad8df",
            "value": 1
          }
        },
        "0eae901446ee439491323fccff027cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fade80dc7b644aaf873c1f2a142b67d3",
            "placeholder": "​",
            "style": "IPY_MODEL_a5b9000d1b164561a1531cf3b0d41202",
            "value": " 458/? [00:01&lt;00:00, 357.86it/s]"
          }
        },
        "8b129c022e674b5baa5450dfe9b98e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85dceb627f854303972077e5e2720e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eda3e2fc4a3474fabe7dd1736d9f207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca040b13f16944b1a391be71866de055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a6f621d682434766864026378b3ad8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fade80dc7b644aaf873c1f2a142b67d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b9000d1b164561a1531cf3b0d41202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80605be75da64f78bec5dbc278121831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a0ca7e197284d5fbc55e58d1b9f5716",
              "IPY_MODEL_6115e4626178464f99988298e4b4dc5e",
              "IPY_MODEL_e3c99f933e704533bc4325c33e0d1d6e"
            ],
            "layout": "IPY_MODEL_fc2045435cfe4477aad6619c68a2572f"
          }
        },
        "2a0ca7e197284d5fbc55e58d1b9f5716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6174b4e20820421f9777b04db837d6f8",
            "placeholder": "​",
            "style": "IPY_MODEL_208e1db0b58747b7bc0b5e77c4a88a49",
            "value": ""
          }
        },
        "6115e4626178464f99988298e4b4dc5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fdc9a4f1d304ffaac37ef55f49ee94f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c65347e436f4b5fbbdf9c0f26efd9c9",
            "value": 1
          }
        },
        "e3c99f933e704533bc4325c33e0d1d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1566def7b64bc090f64bab3eca9c97",
            "placeholder": "​",
            "style": "IPY_MODEL_04986f5e477149afa90bc7e1ac97a6ed",
            "value": " 131/? [00:00&lt;00:00, 290.86it/s]"
          }
        },
        "fc2045435cfe4477aad6619c68a2572f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6174b4e20820421f9777b04db837d6f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "208e1db0b58747b7bc0b5e77c4a88a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fdc9a4f1d304ffaac37ef55f49ee94f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7c65347e436f4b5fbbdf9c0f26efd9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e1566def7b64bc090f64bab3eca9c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04986f5e477149afa90bc7e1ac97a6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6be53730c79e40f0a0a4198f6e2abc5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67574f17453e47dbaf1286a3e2584d6b",
              "IPY_MODEL_b2b8e4fafded4a5dab07cccf36b77e89",
              "IPY_MODEL_e075da1475444852957ce19cd24f0f0e"
            ],
            "layout": "IPY_MODEL_ca8719d7deef4b72bc4411807dc84759"
          }
        },
        "67574f17453e47dbaf1286a3e2584d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ea38c601ea54aefa7a05949ca7ef762",
            "placeholder": "​",
            "style": "IPY_MODEL_fafa0af4bd4a45da92a58f94d5ad03b8",
            "value": ""
          }
        },
        "b2b8e4fafded4a5dab07cccf36b77e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc6492042554a13a63856e36a196c9b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_591c079e26784936ad23f4a4625a3392",
            "value": 1
          }
        },
        "e075da1475444852957ce19cd24f0f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1709303058994cccabfbbc998fc121bd",
            "placeholder": "​",
            "style": "IPY_MODEL_75cfc61b08484f2c87f9ab0fc13adfd2",
            "value": " 66/? [00:00&lt;00:00, 172.84it/s]"
          }
        },
        "ca8719d7deef4b72bc4411807dc84759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ea38c601ea54aefa7a05949ca7ef762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fafa0af4bd4a45da92a58f94d5ad03b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bc6492042554a13a63856e36a196c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "591c079e26784936ad23f4a4625a3392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1709303058994cccabfbbc998fc121bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75cfc61b08484f2c87f9ab0fc13adfd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3vzS1lLxF5E"
      },
      "outputs": [],
      "source": [
        "#!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyTDC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMuBajA7xXCQ",
        "outputId": "b1c08d53-a3ec-4952-f6a0-4a308c417b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyTDC\n",
            "  Downloading PyTDC-0.3.6.tar.gz (88 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 18.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 61 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 71 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 81 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 88 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from PyTDC) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from PyTDC) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from PyTDC) (4.64.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from PyTDC) (1.0.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from PyTDC) (0.11.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->PyTDC) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->PyTDC) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->PyTDC) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->PyTDC) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->PyTDC) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->PyTDC) (3.1.0)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn->PyTDC) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->PyTDC) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->PyTDC) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->PyTDC) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn->PyTDC) (4.2.0)\n",
            "Building wheels for collected packages: PyTDC\n",
            "  Building wheel for PyTDC (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyTDC: filename=PyTDC-0.3.6-py3-none-any.whl size=120882 sha256=b12a3280cadb5826d7f9d82913c78d2c32055d060876d4c7a9aa63307904773c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/54/29/38349b4cf57cda21a1493f61721a6d72b232061f7665102d47\n",
            "Successfully built PyTDC\n",
            "Installing collected packages: fuzzywuzzy, PyTDC\n",
            "Successfully installed PyTDC-0.3.6 fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install sklearn"
      ],
      "metadata": {
        "id": "Ij99__TexfJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install molml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc_GWHmxxoZD",
        "outputId": "b13f3cf2-7153-45cb-ea12-fb9ebea35d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting molml\n",
            "  Downloading molml-0.9.0.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting pathos\n",
            "  Downloading pathos-0.2.8-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from molml) (0.16.0)\n",
            "Collecting bidict\n",
            "  Downloading bidict-0.22.0-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from pathos->molml) (0.3.4)\n",
            "Requirement already satisfied: multiprocess>=0.70.12 in /usr/local/lib/python3.7/dist-packages (from pathos->molml) (0.70.12.2)\n",
            "Collecting pox>=0.3.0\n",
            "  Downloading pox-0.3.1-py2.py3-none-any.whl (28 kB)\n",
            "Collecting ppft>=1.6.6.4\n",
            "  Downloading ppft-1.7.6.5-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 633 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from ppft>=1.6.6.4->pathos->molml) (1.15.0)\n",
            "Building wheels for collected packages: molml\n",
            "  Building wheel for molml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for molml: filename=molml-0.9.0-py3-none-any.whl size=48047 sha256=1d7010abad5383372cd4691bef32bd16559da06677716799d829b465f24c7b10\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/e0/af/d7f31c593ca14b103e3e201575a81773dd264f09f0bd402d9a\n",
            "Successfully built molml\n",
            "Installing collected packages: ppft, pox, pathos, bidict, molml\n",
            "Successfully installed bidict-0.22.0 molml-0.9.0 pathos-0.2.8 pox-0.3.1 ppft-1.7.6.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-py37_4.8.3-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c rdkit rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gj8be9GxsrR",
        "outputId": "5bf2d16d-d7e7-4dde-f892-78fcee77c289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-20 04:54:42--  https://repo.continuum.io/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh [following]\n",
            "--2022-05-20 04:54:43--  https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88867207 (85M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py37_4.8.3-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py37_4.8 100%[===================>]  84.75M   110MB/s    in 0.8s    \n",
            "\n",
            "2022-05-20 04:54:43 (110 MB/s) - ‘Miniconda3-py37_4.8.3-Linux-x86_64.sh’ saved [88867207/88867207]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2020.4.5.1=py37_0\n",
            "    - cffi==1.14.0=py37he30daa8_1\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.1=py37h7b6447c_0\n",
            "    - conda==4.8.3=py37_0\n",
            "    - cryptography==2.9.2=py37h1ba5d50_0\n",
            "    - idna==2.9=py_1\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.3=he6710b0_1\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_1\n",
            "    - openssl==1.1.1g=h7b6447c_0\n",
            "    - pip==20.0.2=py37_3\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.20=py_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.7=hcff3b4d_5\n",
            "    - readline==8.0=h7b6447c_0\n",
            "    - requests==2.23.0=py37_0\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==46.4.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h62c20be_1\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.46.0=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2020.4.5.1-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37he30daa8_1\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.3-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.1-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.9.2-py37h1ba5d50_0\n",
            "  idna               pkgs/main/noarch::idna-2.9-py_1\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_1\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1g-h7b6447c_0\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_3\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.20-py_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.7-hcff3b4d_5\n",
            "  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0\n",
            "  requests           pkgs/main/linux-64::requests-2.23.0-py37_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-46.4.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h62c20be_1\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.46.0-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m30.780s\n",
            "user\t0m17.727s\n",
            "sys\t0m4.704s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-5.1          |            1_gnu          21 KB\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    bottleneck-1.3.4           |   py37hce1f21e_0         126 KB\n",
            "    bzip2-1.0.8                |       h7b6447c_0          78 KB\n",
            "    ca-certificates-2022.4.26  |       h06a4308_0         124 KB\n",
            "    cairo-1.16.0               |       hf32fb01_1         1.0 MB\n",
            "    certifi-2021.10.8          |   py37h06a4308_2         151 KB\n",
            "    conda-4.12.0               |   py37h06a4308_0        14.5 MB\n",
            "    fontconfig-2.13.1          |       h6c09931_0         250 KB\n",
            "    freetype-2.11.0            |       h70c0345_0         618 KB\n",
            "    giflib-5.2.1               |       h7b6447c_0          78 KB\n",
            "    glib-2.69.1                |       h4ff587b_1         1.7 MB\n",
            "    icu-58.2                   |       he6710b0_3        10.5 MB\n",
            "    intel-openmp-2021.4.0      |    h06a4308_3561         4.2 MB\n",
            "    jpeg-9e                    |       h7f8727e_0         240 KB\n",
            "    lcms2-2.12                 |       h3be6417_0         312 KB\n",
            "    libboost-1.73.0            |      h3ff78a5_11        13.9 MB\n",
            "    libgcc-ng-11.2.0           |       h1234567_0         5.3 MB\n",
            "    libgomp-11.2.0             |       h1234567_0         473 KB\n",
            "    libpng-1.6.37              |       hbc83047_0         278 KB\n",
            "    libtiff-4.2.0              |       h85742a9_0         502 KB\n",
            "    libuuid-1.0.3              |       h7f8727e_2          17 KB\n",
            "    libwebp-1.2.2              |       h55f646e_0          80 KB\n",
            "    libwebp-base-1.2.2         |       h7f8727e_0         440 KB\n",
            "    libxcb-1.15                |       h7f8727e_0         505 KB\n",
            "    libxml2-2.9.12             |       h03d6c58_0         1.2 MB\n",
            "    lz4-c-1.9.3                |       h295c915_1         185 KB\n",
            "    mkl-2021.4.0               |     h06a4308_640       142.6 MB\n",
            "    mkl-service-2.4.0          |   py37h7f8727e_0          56 KB\n",
            "    mkl_fft-1.3.1              |   py37hd3c417c_0         172 KB\n",
            "    mkl_random-1.2.2           |   py37h51133e4_0         287 KB\n",
            "    numexpr-2.8.1              |   py37h6abb31d_0         123 KB\n",
            "    numpy-1.21.5               |   py37he7a7128_2          10 KB\n",
            "    numpy-base-1.21.5          |   py37hf524024_2         4.8 MB\n",
            "    openssl-1.1.1o             |       h7f8727e_0         2.5 MB\n",
            "    packaging-21.3             |     pyhd3eb1b0_0          36 KB\n",
            "    pandas-1.3.5               |   py37h8c16a72_0         9.3 MB\n",
            "    pcre-8.45                  |       h295c915_0         207 KB\n",
            "    pillow-9.0.1               |   py37h22f2fdc_0         652 KB\n",
            "    pixman-0.40.0              |       h7f8727e_1         373 KB\n",
            "    py-boost-1.73.0            |  py37ha9443f7_11         204 KB\n",
            "    pyparsing-3.0.4            |     pyhd3eb1b0_0          81 KB\n",
            "    python-dateutil-2.8.2      |     pyhd3eb1b0_0         233 KB\n",
            "    pytz-2021.3                |     pyhd3eb1b0_0         171 KB\n",
            "    rdkit-2020.09.1.0          |   py37hd50e099_1        25.8 MB  rdkit\n",
            "    zstd-1.4.9                 |       haebb681_0         480 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       244.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
            "  bottleneck         pkgs/main/linux-64::bottleneck-1.3.4-py37hce1f21e_0\n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
            "  cairo              pkgs/main/linux-64::cairo-1.16.0-hf32fb01_1\n",
            "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.1-h6c09931_0\n",
            "  freetype           pkgs/main/linux-64::freetype-2.11.0-h70c0345_0\n",
            "  giflib             pkgs/main/linux-64::giflib-5.2.1-h7b6447c_0\n",
            "  glib               pkgs/main/linux-64::glib-2.69.1-h4ff587b_1\n",
            "  icu                pkgs/main/linux-64::icu-58.2-he6710b0_3\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2021.4.0-h06a4308_3561\n",
            "  jpeg               pkgs/main/linux-64::jpeg-9e-h7f8727e_0\n",
            "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0\n",
            "  libboost           pkgs/main/linux-64::libboost-1.73.0-h3ff78a5_11\n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_0\n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.2.0-h85742a9_0\n",
            "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h7f8727e_2\n",
            "  libwebp            pkgs/main/linux-64::libwebp-1.2.2-h55f646e_0\n",
            "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.2-h7f8727e_0\n",
            "  libxcb             pkgs/main/linux-64::libxcb-1.15-h7f8727e_0\n",
            "  libxml2            pkgs/main/linux-64::libxml2-2.9.12-h03d6c58_0\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.3-h295c915_1\n",
            "  mkl                pkgs/main/linux-64::mkl-2021.4.0-h06a4308_640\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.4.0-py37h7f8727e_0\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.1-py37hd3c417c_0\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.2.2-py37h51133e4_0\n",
            "  numexpr            pkgs/main/linux-64::numexpr-2.8.1-py37h6abb31d_0\n",
            "  numpy              pkgs/main/linux-64::numpy-1.21.5-py37he7a7128_2\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.21.5-py37hf524024_2\n",
            "  packaging          pkgs/main/noarch::packaging-21.3-pyhd3eb1b0_0\n",
            "  pandas             pkgs/main/linux-64::pandas-1.3.5-py37h8c16a72_0\n",
            "  pcre               pkgs/main/linux-64::pcre-8.45-h295c915_0\n",
            "  pillow             pkgs/main/linux-64::pillow-9.0.1-py37h22f2fdc_0\n",
            "  pixman             pkgs/main/linux-64::pixman-0.40.0-h7f8727e_1\n",
            "  py-boost           pkgs/main/linux-64::py-boost-1.73.0-py37ha9443f7_11\n",
            "  pyparsing          pkgs/main/noarch::pyparsing-3.0.4-pyhd3eb1b0_0\n",
            "  python-dateutil    pkgs/main/noarch::python-dateutil-2.8.2-pyhd3eb1b0_0\n",
            "  pytz               pkgs/main/noarch::pytz-2021.3-pyhd3eb1b0_0\n",
            "  rdkit              rdkit/linux-64::rdkit-2020.09.1.0-py37hd50e099_1\n",
            "  zstd               pkgs/main/linux-64::zstd-1.4.9-haebb681_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                                2020.1.1-0 --> 2022.4.26-h06a4308_0\n",
            "  certifi                                 2020.4.5.1-py37_0 --> 2021.10.8-py37h06a4308_2\n",
            "  conda                                        4.8.3-py37_0 --> 4.12.0-py37h06a4308_0\n",
            "  libgcc-ng                                9.1.0-hdf63c60_0 --> 11.2.0-h1234567_0\n",
            "  openssl                                 1.1.1g-h7b6447c_0 --> 1.1.1o-h7f8727e_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m38.398s\n",
            "user\t0m20.735s\n",
            "sys\t0m8.778s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "metadata": {
        "id": "2HLaIHURx4xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy.io import loadmat\n",
        "from tqdm.auto import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ],
      "metadata": {
        "id": "ZfQkVzdox9ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "38zg-7AFyOf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import molml\n",
        "from rdkit import Chem\n",
        "from molml.features import BagOfBonds\n",
        "import csv\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import math\n",
        "import random\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import rdkit, rdkit.Chem.AllChem, rdkit.Chem.Crippen\n",
        "import rdkit.Chem as Chem\n",
        "from rdkit.Chem import Draw"
      ],
      "metadata": {
        "id": "wlgffVlwycE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem"
      ],
      "metadata": {
        "id": "KsaHKoXIypzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tdc.single_pred import Tox\n",
        "data = Tox(name = 'hERG')\n",
        "split = data.get_split(method = 'random', seed = 42, frac = [0.7, 0.1, 0.2])\n",
        "# split: {'train': train dataframe, 'valid': valid dataframe, 'test': test dataframe}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mD3qJifACBC",
        "outputId": "57d9404d-6dda-42fe-cbd4-a0b9f916ec8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "100%|██████████| 50.2k/50.2k [00:00<00:00, 917kiB/s]\n",
            "Loading...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_tox=split['train']"
      ],
      "metadata": {
        "id": "0ZVuXPRXASdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_tox.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RU7HNxU5Dtmi",
        "outputId": "6048eab1-55b9-45f2-d0f5-3ed7643b5a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Drug_ID  \\\n",
              "0        DEMETHYLASTEMIZOLE   \n",
              "1                 GBR-12909   \n",
              "2       CLOFILIUM PHOSPHATE   \n",
              "3              FLUSPIRILENE   \n",
              "4  VANOXERINE HYDROCHLORIDE   \n",
              "\n",
              "                                                Drug    Y  \n",
              "0  Oc1ccc(CCN2CCC(Nc3nc4ccccc4n3Cc3ccc(F)cc3)CC2)cc1  1.0  \n",
              "1  Fc1ccc(C(OCC[NH+]2CC[NH+](CCCc3ccccc3)CC2)c2cc...  1.0  \n",
              "2  CCCCCCC[N+](CC)(CC)CCCCc1ccc(Cl)cc1.CCCCCCC[N+...  1.0  \n",
              "3  O=C1NCN(c2ccccc2)C12CC[NH+](CCCC(c1ccc(F)cc1)c...  1.0  \n",
              "4  Fc1ccc(C(OCCN2CCN(CCCc3ccccc3)CC2)c2ccc(F)cc2)cc1  1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-581f9328-4490-4d69-8bd6-fe91032c944a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Drug_ID</th>\n",
              "      <th>Drug</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DEMETHYLASTEMIZOLE</td>\n",
              "      <td>Oc1ccc(CCN2CCC(Nc3nc4ccccc4n3Cc3ccc(F)cc3)CC2)cc1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GBR-12909</td>\n",
              "      <td>Fc1ccc(C(OCC[NH+]2CC[NH+](CCCc3ccccc3)CC2)c2cc...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CLOFILIUM PHOSPHATE</td>\n",
              "      <td>CCCCCCC[N+](CC)(CC)CCCCc1ccc(Cl)cc1.CCCCCCC[N+...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FLUSPIRILENE</td>\n",
              "      <td>O=C1NCN(c2ccccc2)C12CC[NH+](CCCC(c1ccc(F)cc1)c...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VANOXERINE HYDROCHLORIDE</td>\n",
              "      <td>Fc1ccc(C(OCCN2CCN(CCCc3ccccc3)CC2)c2ccc(F)cc2)cc1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-581f9328-4490-4d69-8bd6-fe91032c944a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-581f9328-4490-4d69-8bd6-fe91032c944a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-581f9328-4490-4d69-8bd6-fe91032c944a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_tox.set_index('Drug_ID',inplace = True)"
      ],
      "metadata": {
        "id": "goSlpNeRyrjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_tox.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGInY8NJGibs",
        "outputId": "5738295d-de03-4ff2-d7af-bc4fb1a64692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Drug', 'Y'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_tox.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuZywvxyRNOP",
        "outputId": "035906ed-86c5-4c8d-8a97-83c18609a071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 458 entries, DEMETHYLASTEMIZOLE to TOLCAPONE\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Drug    458 non-null    object \n",
            " 1   Y       458 non-null    float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 10.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_tox.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmd3JeKbAu77",
        "outputId": "9d7f0b69-1a7a-48c3-8340-d4294948dde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(458, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_tox=split['test']"
      ],
      "metadata": {
        "id": "b1Zs11XYA07r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_tox.set_index('Drug_ID',inplace = True)"
      ],
      "metadata": {
        "id": "tqvRWLGCzbFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_tox.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BLYJE1mA8ov",
        "outputId": "1d0d5b13-eadd-4df6-b396-6e2a5530a014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val_tox=split['valid']"
      ],
      "metadata": {
        "id": "hGKP5QqnBEye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val_tox.set_index('Drug_ID',inplace = True)"
      ],
      "metadata": {
        "id": "8Qy0-nu0zfrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val_tox.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnJv4hEjBR_p",
        "outputId": "26197f5f-e80d-47a6-8e89-a34978bcbdfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment: Toxicity classification\n",
        "\n",
        "You are given a dataset of SMILES and whether they are toxic or not. Task is to create a neural network model for predicting whether a given molecule is toxic or not"
      ],
      "metadata": {
        "id": "vnb-g1v0yQ3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "zK6A0cVHxzPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train=df_train_tox[['Y']]\n",
        "Y_test=df_test_tox[['Y']]\n",
        "Y_val=df_val_tox[['Y']]"
      ],
      "metadata": {
        "id": "ryBIaxZnBZvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train.shape,Y_val.shape,Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk9SnVAs0Dtd",
        "outputId": "4de0ee55-5275-436f-ef37-7c1248eaff2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(458, 1) (66, 1) (131, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "c-H_gQ3F24YY",
        "outputId": "27c3be0b-1ce3-40d4-f5e6-7c9e0b521651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Y\n",
              "Drug_ID        \n",
              "NELFINAVIR  1.0\n",
              "WAY123398   1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-231a00dd-81db-49ed-ae67-1e5111e34d0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Drug_ID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NELFINAVIR</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WAY123398</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-231a00dd-81db-49ed-ae67-1e5111e34d0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-231a00dd-81db-49ed-ae67-1e5111e34d0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-231a00dd-81db-49ed-ae67-1e5111e34d0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_tox = df_train_tox[['Drug']]\n",
        "X_train = []\n",
        "\n",
        "for idx, row in tqdm(df_train_tox.iterrows()):\n",
        "  drug = row['Drug']\n",
        "  #tox_class = row['Y']\n",
        "  fingerprint = np.asarray(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(drug),2,nBits=512))\n",
        "  X_train.append(fingerprint)\n",
        "X_train = np.vstack(X_train)\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0bf6ca46c5344e0db33b08f6ef7c1126",
            "7f907e213c234ec88f5445893f24a765",
            "80d27f1cf9194563861a1a519d76c53a",
            "0eae901446ee439491323fccff027cfb",
            "8b129c022e674b5baa5450dfe9b98e32",
            "85dceb627f854303972077e5e2720e47",
            "7eda3e2fc4a3474fabe7dd1736d9f207",
            "ca040b13f16944b1a391be71866de055",
            "a6f621d682434766864026378b3ad8df",
            "fade80dc7b644aaf873c1f2a142b67d3",
            "a5b9000d1b164561a1531cf3b0d41202"
          ]
        },
        "id": "HukStSxh_OII",
        "outputId": "c574f710-c15d-495f-af47-349390939449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bf6ca46c5344e0db33b08f6ef7c1126"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(458, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_test_tox = df_test_tox[['Drug']]\n",
        "df_val_tox = df_val_tox[['Drug']]\n",
        "\n",
        "X_test =[]\n",
        "X_valid =[]\n",
        "\n",
        "for idx, row in tqdm(df_test_tox.iterrows()):\n",
        "  drug = row['Drug']\n",
        "  #tox_class = row['Y']\n",
        "  fingerprint = np.asarray(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(drug),2,nBits=512))\n",
        "  X_test.append(fingerprint)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "for idx, row in tqdm(df_val_tox.iterrows()):\n",
        "  drug = row['Drug']\n",
        "  #tox_class = row['Y']\n",
        "  fingerprint = np.asarray(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(drug),2,nBits=512))\n",
        "  X_valid.append(fingerprint)\n",
        "X_valid = np.vstack(X_valid)\n",
        "\n",
        "print(X_valid.shape,X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "80605be75da64f78bec5dbc278121831",
            "2a0ca7e197284d5fbc55e58d1b9f5716",
            "6115e4626178464f99988298e4b4dc5e",
            "e3c99f933e704533bc4325c33e0d1d6e",
            "fc2045435cfe4477aad6619c68a2572f",
            "6174b4e20820421f9777b04db837d6f8",
            "208e1db0b58747b7bc0b5e77c4a88a49",
            "9fdc9a4f1d304ffaac37ef55f49ee94f",
            "7c65347e436f4b5fbbdf9c0f26efd9c9",
            "9e1566def7b64bc090f64bab3eca9c97",
            "04986f5e477149afa90bc7e1ac97a6ed",
            "6be53730c79e40f0a0a4198f6e2abc5e",
            "67574f17453e47dbaf1286a3e2584d6b",
            "b2b8e4fafded4a5dab07cccf36b77e89",
            "e075da1475444852957ce19cd24f0f0e",
            "ca8719d7deef4b72bc4411807dc84759",
            "2ea38c601ea54aefa7a05949ca7ef762",
            "fafa0af4bd4a45da92a58f94d5ad03b8",
            "3bc6492042554a13a63856e36a196c9b",
            "591c079e26784936ad23f4a4625a3392",
            "1709303058994cccabfbbc998fc121bd",
            "75cfc61b08484f2c87f9ab0fc13adfd2"
          ]
        },
        "id": "UAVJfNw18a3u",
        "outputId": "369633b3-630a-4430-810a-424918ddefbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80605be75da64f78bec5dbc278121831"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6be53730c79e40f0a0a4198f6e2abc5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(66, 512) (131, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=pd.DataFrame(X_train)"
      ],
      "metadata": {
        "id": "m8EH726c2KM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=pd.DataFrame(X_test)"
      ],
      "metadata": {
        "id": "Lyr0EZRgCPtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid=pd.DataFrame(X_valid)"
      ],
      "metadata": {
        "id": "OFtVnN2hCP0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Vsvo33-X2iNF",
        "outputId": "db6c0ec7-e609-4106-f52d-bee0f8af779f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0    1    2    3    4    5    6    7    8    9    ...  502  503  504  505  \\\n",
              "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "1    0    1    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
              "\n",
              "   506  507  508  509  510  511  \n",
              "0    0    1    0    0    0    0  \n",
              "1    0    0    0    0    0    0  \n",
              "\n",
              "[2 rows x 512 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ba47590-cd13-4806-bf74-f369b2d39c9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 512 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ba47590-cd13-4806-bf74-f369b2d39c9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ba47590-cd13-4806-bf74-f369b2d39c9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ba47590-cd13-4806-bf74-f369b2d39c9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        \n",
        "        n_features = 512\n",
        "        \n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(n_features, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 1),\n",
        "    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMOewtEbyY42",
        "outputId": "9db1f11f-ba26-478b-d326-9bb401144199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 512\n",
        "X = torch.rand(10, n_features, device=device)\n",
        "\n",
        "predictions = model(X)\n",
        "print(f\"Predicted class: {predictions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Eec4qqVRyZv",
        "outputId": "440bf443-9e9f-4508-9d0c-fb70a8a541b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([[-0.0206],\n",
            "        [-0.0383],\n",
            "        [-0.0359],\n",
            "        [-0.0471],\n",
            "        [-0.0384],\n",
            "        [-0.0676],\n",
            "        [-0.0583],\n",
            "        [-0.0899],\n",
            "        [-0.0751],\n",
            "        [-0.0297]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.rand(10, n_features, device=device)\n",
        "print(input_tensor.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW0T4PCfaJ8P",
        "outputId": "e9097281-ca93-43be-92e8-5674a20ae801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = nn.Linear(in_features=n_features, out_features=256).to(device)\n",
        "hidden1 = layer1(input_tensor)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzsH8igsaTVp",
        "outputId": "084d7ffa-5b52-42fb-9508-dad219d5160a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 1)\n",
        ").to(device)\n",
        "\n",
        "\n",
        "input_tensor = torch.rand(10,n_features, device=device)\n",
        "logits = seq_modules(input_tensor)\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ckHkdZ4RyfD",
        "outputId": "76abe2a8-df9d-4d54-c5a5-0b9b158508c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2018],\n",
            "        [-0.0975],\n",
            "        [-0.1289],\n",
            "        [-0.0968],\n",
            "        [-0.1339],\n",
            "        [-0.1329],\n",
            "        [-0.1725],\n",
            "        [-0.1925],\n",
            "        [-0.1628],\n",
            "        [-0.1505]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6lDJs7rafgE",
        "outputId": "55508e96-fa0f-4b41-bac6-607026af2c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[-0.4280,  0.0824,  0.0462,  ..., -0.3402,  0.2337, -0.2650],\n",
            "        [-0.4989, -0.2195, -0.0138,  ..., -0.5435,  0.0339, -0.2160],\n",
            "        [-0.2366, -0.0941, -0.0747,  ..., -0.3352,  0.0012, -0.3770],\n",
            "        ...,\n",
            "        [-0.3965, -0.2978, -0.1461,  ..., -0.3877, -0.2799, -0.1048],\n",
            "        [-0.3355,  0.0669,  0.2023,  ..., -0.1176, -0.1645, -0.1168],\n",
            "        [-0.1825, -0.1410,  0.3221,  ..., -0.3300,  0.1637, -0.2423]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.0000, 0.0824, 0.0462,  ..., 0.0000, 0.2337, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0339, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0012, 0.0000],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0669, 0.2023,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.3221,  ..., 0.0000, 0.1637, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn9LoXskayDI",
        "outputId": "3b0d24d3-32bd-40f0-fb8a-f437ea68e0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([256, 512]) | Values : tensor([[ 0.0371,  0.0063,  0.0184,  ..., -0.0317, -0.0372,  0.0259],\n",
            "        [-0.0249,  0.0150,  0.0438,  ...,  0.0129,  0.0068, -0.0064]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([256]) | Values : tensor([-0.0298, -0.0249], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([128, 256]) | Values : tensor([[ 0.0147, -0.0436,  0.0033, -0.0282,  0.0583,  0.0244, -0.0578,  0.0491,\n",
            "          0.0563, -0.0344,  0.0058,  0.0559,  0.0262,  0.0124, -0.0579,  0.0089,\n",
            "         -0.0492,  0.0086, -0.0069, -0.0101, -0.0448, -0.0610, -0.0037,  0.0211,\n",
            "          0.0244, -0.0173,  0.0146,  0.0058, -0.0309,  0.0590, -0.0255,  0.0332,\n",
            "          0.0224,  0.0221, -0.0024, -0.0020,  0.0223,  0.0109, -0.0327, -0.0096,\n",
            "          0.0144,  0.0433, -0.0193, -0.0420,  0.0030,  0.0508,  0.0327, -0.0227,\n",
            "         -0.0038, -0.0106, -0.0351,  0.0156,  0.0361, -0.0320,  0.0229, -0.0351,\n",
            "         -0.0059, -0.0583, -0.0248, -0.0228, -0.0062,  0.0491,  0.0549, -0.0230,\n",
            "          0.0179, -0.0002, -0.0303,  0.0533,  0.0155,  0.0497,  0.0386,  0.0227,\n",
            "         -0.0481,  0.0118,  0.0158,  0.0160, -0.0385,  0.0208, -0.0548,  0.0182,\n",
            "         -0.0167, -0.0532, -0.0406,  0.0450,  0.0187,  0.0350, -0.0530, -0.0011,\n",
            "         -0.0619, -0.0476,  0.0365, -0.0516, -0.0302,  0.0259, -0.0357, -0.0193,\n",
            "          0.0283,  0.0138, -0.0295,  0.0508, -0.0085, -0.0500,  0.0211, -0.0392,\n",
            "          0.0276, -0.0150,  0.0132, -0.0172,  0.0438,  0.0104,  0.0022,  0.0166,\n",
            "          0.0224, -0.0220,  0.0522, -0.0570,  0.0029,  0.0050, -0.0491, -0.0551,\n",
            "         -0.0156, -0.0614, -0.0344,  0.0233,  0.0274, -0.0214, -0.0543, -0.0241,\n",
            "         -0.0184,  0.0568,  0.0368, -0.0366, -0.0576,  0.0277, -0.0375, -0.0216,\n",
            "          0.0611,  0.0087, -0.0459, -0.0518, -0.0161,  0.0011, -0.0144, -0.0166,\n",
            "         -0.0340,  0.0412, -0.0569, -0.0099,  0.0165, -0.0148,  0.0031, -0.0294,\n",
            "         -0.0398, -0.0532,  0.0509, -0.0292, -0.0431,  0.0545,  0.0614, -0.0092,\n",
            "          0.0243, -0.0291, -0.0201,  0.0476, -0.0189, -0.0138,  0.0292,  0.0357,\n",
            "          0.0485, -0.0625,  0.0068, -0.0046, -0.0357, -0.0370, -0.0054, -0.0080,\n",
            "         -0.0026, -0.0525,  0.0418,  0.0560,  0.0492, -0.0376,  0.0536,  0.0115,\n",
            "         -0.0597,  0.0396, -0.0615,  0.0458, -0.0317,  0.0467,  0.0428,  0.0260,\n",
            "         -0.0128,  0.0187, -0.0603,  0.0535,  0.0389,  0.0120, -0.0010, -0.0109,\n",
            "         -0.0261,  0.0157, -0.0468,  0.0095,  0.0417, -0.0251, -0.0382,  0.0477,\n",
            "         -0.0490,  0.0522, -0.0586, -0.0068,  0.0239, -0.0470,  0.0324,  0.0218,\n",
            "          0.0209,  0.0340,  0.0241, -0.0254, -0.0354, -0.0609, -0.0526, -0.0395,\n",
            "         -0.0614,  0.0484, -0.0037,  0.0033, -0.0363,  0.0189,  0.0019,  0.0394,\n",
            "         -0.0427,  0.0440, -0.0524,  0.0285, -0.0151,  0.0193,  0.0418,  0.0254,\n",
            "         -0.0013, -0.0532, -0.0141, -0.0486,  0.0284,  0.0016,  0.0046,  0.0568,\n",
            "         -0.0225, -0.0512,  0.0463,  0.0618, -0.0265, -0.0072,  0.0578, -0.0274],\n",
            "        [ 0.0049, -0.0096,  0.0152,  0.0372,  0.0483, -0.0222,  0.0550,  0.0225,\n",
            "         -0.0023,  0.0309,  0.0133,  0.0548, -0.0431,  0.0405,  0.0074,  0.0338,\n",
            "         -0.0320,  0.0185,  0.0435,  0.0114, -0.0601,  0.0293, -0.0584,  0.0532,\n",
            "         -0.0026,  0.0477,  0.0239, -0.0360, -0.0248, -0.0041,  0.0099, -0.0412,\n",
            "         -0.0432,  0.0429,  0.0598, -0.0261,  0.0112,  0.0373, -0.0509,  0.0593,\n",
            "          0.0015,  0.0186, -0.0440, -0.0076, -0.0348,  0.0383,  0.0519, -0.0509,\n",
            "          0.0303,  0.0283,  0.0045, -0.0085,  0.0097,  0.0565, -0.0232,  0.0184,\n",
            "         -0.0421, -0.0483, -0.0551, -0.0464, -0.0601,  0.0556, -0.0403, -0.0218,\n",
            "         -0.0544, -0.0116, -0.0294,  0.0397,  0.0185, -0.0252,  0.0065, -0.0281,\n",
            "          0.0292, -0.0322, -0.0245, -0.0112,  0.0291, -0.0351,  0.0248, -0.0033,\n",
            "          0.0399, -0.0377, -0.0300, -0.0328,  0.0452,  0.0512,  0.0258, -0.0490,\n",
            "          0.0616, -0.0500,  0.0015,  0.0438,  0.0283,  0.0030, -0.0562,  0.0278,\n",
            "         -0.0610, -0.0550, -0.0073,  0.0440, -0.0389,  0.0096, -0.0170,  0.0372,\n",
            "          0.0190,  0.0025,  0.0205,  0.0277,  0.0021, -0.0153, -0.0147,  0.0466,\n",
            "          0.0185,  0.0247, -0.0254, -0.0611,  0.0611, -0.0056,  0.0435,  0.0142,\n",
            "          0.0251,  0.0188,  0.0549, -0.0104,  0.0009,  0.0097,  0.0534,  0.0138,\n",
            "         -0.0621,  0.0185,  0.0320, -0.0436,  0.0542, -0.0358,  0.0083, -0.0352,\n",
            "          0.0503,  0.0146,  0.0009,  0.0590, -0.0306, -0.0171, -0.0110,  0.0345,\n",
            "          0.0235, -0.0075, -0.0481, -0.0046,  0.0128,  0.0184, -0.0569,  0.0317,\n",
            "         -0.0370,  0.0464,  0.0527, -0.0190, -0.0376, -0.0415, -0.0271, -0.0498,\n",
            "          0.0156, -0.0117,  0.0470,  0.0197, -0.0034,  0.0092, -0.0187, -0.0436,\n",
            "         -0.0328,  0.0126, -0.0148,  0.0581, -0.0042, -0.0135, -0.0219, -0.0214,\n",
            "         -0.0127, -0.0191, -0.0111,  0.0021,  0.0575,  0.0526,  0.0057, -0.0108,\n",
            "          0.0005,  0.0037,  0.0603, -0.0170, -0.0013,  0.0466,  0.0354,  0.0101,\n",
            "         -0.0240, -0.0101, -0.0143, -0.0087, -0.0622,  0.0055, -0.0456, -0.0481,\n",
            "         -0.0105, -0.0412, -0.0180, -0.0601, -0.0321, -0.0382, -0.0575, -0.0609,\n",
            "          0.0201, -0.0361,  0.0610, -0.0135, -0.0516,  0.0118,  0.0257,  0.0547,\n",
            "          0.0555,  0.0327, -0.0406, -0.0586, -0.0275, -0.0245,  0.0236, -0.0592,\n",
            "          0.0529, -0.0505,  0.0129, -0.0427, -0.0392, -0.0531, -0.0560, -0.0190,\n",
            "          0.0441, -0.0037, -0.0492, -0.0525,  0.0502,  0.0106, -0.0452,  0.0509,\n",
            "         -0.0354,  0.0321, -0.0244,  0.0199, -0.0424,  0.0331,  0.0268,  0.0552,\n",
            "         -0.0347, -0.0376, -0.0550, -0.0446, -0.0618,  0.0552,  0.0283, -0.0611]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([128]) | Values : tensor([0.0540, 0.0405], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([1, 128]) | Values : tensor([[ 0.0390, -0.0446,  0.0168, -0.0096,  0.0577, -0.0334,  0.0669,  0.0129,\n",
            "          0.0760, -0.0554,  0.0363, -0.0655, -0.0782, -0.0879, -0.0670,  0.0702,\n",
            "         -0.0021,  0.0517,  0.0430, -0.0652, -0.0191, -0.0640,  0.0631,  0.0020,\n",
            "         -0.0021, -0.0585, -0.0048, -0.0357, -0.0201, -0.0587,  0.0252, -0.0544,\n",
            "          0.0072, -0.0702,  0.0606, -0.0844, -0.0236, -0.0666, -0.0268, -0.0337,\n",
            "          0.0727, -0.0200,  0.0784, -0.0569,  0.0376, -0.0038, -0.0625,  0.0664,\n",
            "          0.0598,  0.0580,  0.0059, -0.0763,  0.0291, -0.0458, -0.0214, -0.0559,\n",
            "          0.0349, -0.0298,  0.0132, -0.0381, -0.0439, -0.0864,  0.0506, -0.0396,\n",
            "         -0.0775,  0.0376,  0.0506, -0.0139, -0.0506, -0.0229, -0.0856, -0.0101,\n",
            "          0.0558,  0.0277, -0.0245,  0.0323,  0.0371,  0.0042,  0.0859,  0.0543,\n",
            "         -0.0118, -0.0641, -0.0212, -0.0252, -0.0207, -0.0359, -0.0591, -0.0700,\n",
            "         -0.0743,  0.0318,  0.0717, -0.0805,  0.0781, -0.0383, -0.0289,  0.0209,\n",
            "          0.0575,  0.0221,  0.0855,  0.0830, -0.0264,  0.0168,  0.0867,  0.0592,\n",
            "          0.0724,  0.0521, -0.0666,  0.0397,  0.0424,  0.0181, -0.0818,  0.0734,\n",
            "          0.0273, -0.0194, -0.0513,  0.0812, -0.0002, -0.0726, -0.0222, -0.0192,\n",
            "          0.0753,  0.0285,  0.0223, -0.0776,  0.0608,  0.0828, -0.0005,  0.0816]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([1]) | Values : tensor([0.0166], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NN hyperparameters\n",
        "input_tensor = torch.rand(10, n_features, device=device)\n",
        "print(input_tensor.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhEhb5hma7xA",
        "outputId": "811bae4d-2565-4c8a-9b60-be45eeb98d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-2\n",
        "batch_size = 64\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "xKkblVr0a_FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the loss function\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n"
      ],
      "metadata": {
        "id": "bPiiSDSKbCFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "qhdravKPbLCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_acc(y_pred, y_test):\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
        "    acc = correct_results_sum/y_test.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ],
      "metadata": {
        "id": "330VwuYE76G3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(X_train, Y_train, loss_fn, optimizer):\n",
        "    size = len(X_train)\n",
        "    batch_size = 32\n",
        "    n_batches = int(size/batch_size)\n",
        "    epochs = 1000\n",
        "\n",
        "    for epoch_id in range(epochs):\n",
        "      running_loss = []\n",
        "      epoch_acc=[]\n",
        "      for batch_id in range(n_batches):\n",
        "          X_batch = X_train[batch_id*batch_size: (batch_id+1)*batch_size]\n",
        "          Y_batch = Y_train[batch_id*batch_size: (batch_id+1)*batch_size]\n",
        "          X_batch = np.array(X_batch)\n",
        "          Y_batch = np.array(Y_batch)\n",
        "          X_batch = torch.FloatTensor(X_batch)\n",
        "          Y_batch = torch.FloatTensor(Y_batch)\n",
        "\n",
        "          # Compute prediction and loss\n",
        "          pred = model(X_batch)\n",
        "          loss = loss_fn (pred, Y_batch)\n",
        "          acc = binary_acc(pred, Y_batch)\n",
        "          running_loss.append(loss.item())\n",
        "          epoch_acc.append(acc.item())\n",
        "          # Backpropagation\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          loss, current = loss.item(), batch_id * len(X)\n",
        "      #print(f'Epoch {epoch_id}: | Loss: {running_loss/len(X_train):>.7f} | Acc: {epoch_acc/len(X_train):.3f}')\n",
        "      print(f\" Epoch: {epoch_id} loss: {np.mean(running_loss):>7f}\")\n"
      ],
      "metadata": {
        "id": "7H7ut7TWRwz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loop(X_train, Y_train, loss_fn, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6PgAWarNk72",
        "outputId": "afd967fb-8e45-4c15-e6b4-b094bfcaaa95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch: 0 loss: 9.426101\n",
            " Epoch: 1 loss: 0.627769\n",
            " Epoch: 2 loss: 0.701935\n",
            " Epoch: 3 loss: 0.754124\n",
            " Epoch: 4 loss: 0.556815\n",
            " Epoch: 5 loss: 0.620072\n",
            " Epoch: 6 loss: 0.437075\n",
            " Epoch: 7 loss: 0.384770\n",
            " Epoch: 8 loss: 0.325142\n",
            " Epoch: 9 loss: 0.286362\n",
            " Epoch: 10 loss: 0.261446\n",
            " Epoch: 11 loss: 0.240076\n",
            " Epoch: 12 loss: 0.221570\n",
            " Epoch: 13 loss: 0.216077\n",
            " Epoch: 14 loss: 0.198880\n",
            " Epoch: 15 loss: 0.189802\n",
            " Epoch: 16 loss: 0.179968\n",
            " Epoch: 17 loss: 0.176478\n",
            " Epoch: 18 loss: 0.164564\n",
            " Epoch: 19 loss: 0.155524\n",
            " Epoch: 20 loss: 0.146171\n",
            " Epoch: 21 loss: 0.135905\n",
            " Epoch: 22 loss: 0.127081\n",
            " Epoch: 23 loss: 0.117260\n",
            " Epoch: 24 loss: 0.111201\n",
            " Epoch: 25 loss: 0.104040\n",
            " Epoch: 26 loss: 0.097928\n",
            " Epoch: 27 loss: 0.093086\n",
            " Epoch: 28 loss: 0.088174\n",
            " Epoch: 29 loss: 0.084753\n",
            " Epoch: 30 loss: 0.082020\n",
            " Epoch: 31 loss: 0.079774\n",
            " Epoch: 32 loss: 0.078072\n",
            " Epoch: 33 loss: 0.076396\n",
            " Epoch: 34 loss: 0.075045\n",
            " Epoch: 35 loss: 0.072640\n",
            " Epoch: 36 loss: 0.070982\n",
            " Epoch: 37 loss: 0.069940\n",
            " Epoch: 38 loss: 0.069102\n",
            " Epoch: 39 loss: 0.068422\n",
            " Epoch: 40 loss: 0.067859\n",
            " Epoch: 41 loss: 0.068391\n",
            " Epoch: 42 loss: 0.067814\n",
            " Epoch: 43 loss: 0.067450\n",
            " Epoch: 44 loss: 0.067085\n",
            " Epoch: 45 loss: 0.066624\n",
            " Epoch: 46 loss: 0.066052\n",
            " Epoch: 47 loss: 0.065039\n",
            " Epoch: 48 loss: 0.064002\n",
            " Epoch: 49 loss: 0.061751\n",
            " Epoch: 50 loss: 0.060394\n",
            " Epoch: 51 loss: 0.055620\n",
            " Epoch: 52 loss: 0.053497\n",
            " Epoch: 53 loss: 0.051739\n",
            " Epoch: 54 loss: 0.050365\n",
            " Epoch: 55 loss: 0.048663\n",
            " Epoch: 56 loss: 0.047990\n",
            " Epoch: 57 loss: 0.047291\n",
            " Epoch: 58 loss: 0.045955\n",
            " Epoch: 59 loss: 0.051560\n",
            " Epoch: 60 loss: 0.044444\n",
            " Epoch: 61 loss: 0.044425\n",
            " Epoch: 62 loss: 0.073581\n",
            " Epoch: 63 loss: 0.046771\n",
            " Epoch: 64 loss: 0.040506\n",
            " Epoch: 65 loss: 0.033995\n",
            " Epoch: 66 loss: 0.036439\n",
            " Epoch: 67 loss: 0.035493\n",
            " Epoch: 68 loss: 0.034408\n",
            " Epoch: 69 loss: 0.033945\n",
            " Epoch: 70 loss: 0.033576\n",
            " Epoch: 71 loss: 0.033153\n",
            " Epoch: 72 loss: 0.043561\n",
            " Epoch: 73 loss: 0.037620\n",
            " Epoch: 74 loss: 0.032019\n",
            " Epoch: 75 loss: 0.029141\n",
            " Epoch: 76 loss: 0.028806\n",
            " Epoch: 77 loss: 0.028558\n",
            " Epoch: 78 loss: 0.093966\n",
            " Epoch: 79 loss: 0.068281\n",
            " Epoch: 80 loss: 1.026815\n",
            " Epoch: 81 loss: 1.187856\n",
            " Epoch: 82 loss: 0.683343\n",
            " Epoch: 83 loss: 0.313861\n",
            " Epoch: 84 loss: 0.267497\n",
            " Epoch: 85 loss: 0.160791\n",
            " Epoch: 86 loss: 0.125915\n",
            " Epoch: 87 loss: 0.098886\n",
            " Epoch: 88 loss: 0.090142\n",
            " Epoch: 89 loss: 0.080020\n",
            " Epoch: 90 loss: 0.074860\n",
            " Epoch: 91 loss: 0.070903\n",
            " Epoch: 92 loss: 0.067871\n",
            " Epoch: 93 loss: 0.065890\n",
            " Epoch: 94 loss: 0.064022\n",
            " Epoch: 95 loss: 0.062618\n",
            " Epoch: 96 loss: 0.061502\n",
            " Epoch: 97 loss: 0.060911\n",
            " Epoch: 98 loss: 0.060475\n",
            " Epoch: 99 loss: 0.060141\n",
            " Epoch: 100 loss: 0.059868\n",
            " Epoch: 101 loss: 0.059697\n",
            " Epoch: 102 loss: 0.059524\n",
            " Epoch: 103 loss: 0.059679\n",
            " Epoch: 104 loss: 0.054214\n",
            " Epoch: 105 loss: 0.052301\n",
            " Epoch: 106 loss: 0.052129\n",
            " Epoch: 107 loss: 0.051964\n",
            " Epoch: 108 loss: 0.051846\n",
            " Epoch: 109 loss: 0.051755\n",
            " Epoch: 110 loss: 0.051696\n",
            " Epoch: 111 loss: 0.051640\n",
            " Epoch: 112 loss: 0.051596\n",
            " Epoch: 113 loss: 0.051561\n",
            " Epoch: 114 loss: 0.051529\n",
            " Epoch: 115 loss: 0.051502\n",
            " Epoch: 116 loss: 0.051482\n",
            " Epoch: 117 loss: 0.051467\n",
            " Epoch: 118 loss: 0.051447\n",
            " Epoch: 119 loss: 0.051430\n",
            " Epoch: 120 loss: 0.051411\n",
            " Epoch: 121 loss: 0.051398\n",
            " Epoch: 122 loss: 0.051391\n",
            " Epoch: 123 loss: 0.051371\n",
            " Epoch: 124 loss: 0.053144\n",
            " Epoch: 125 loss: 0.051390\n",
            " Epoch: 126 loss: 0.051713\n",
            " Epoch: 127 loss: 0.051684\n",
            " Epoch: 128 loss: 0.057437\n",
            " Epoch: 129 loss: 0.052587\n",
            " Epoch: 130 loss: 0.051792\n",
            " Epoch: 131 loss: 0.051839\n",
            " Epoch: 132 loss: 0.051586\n",
            " Epoch: 133 loss: 0.051435\n",
            " Epoch: 134 loss: 0.051399\n",
            " Epoch: 135 loss: 0.051400\n",
            " Epoch: 136 loss: 0.051389\n",
            " Epoch: 137 loss: 0.051378\n",
            " Epoch: 138 loss: 0.051365\n",
            " Epoch: 139 loss: 0.051345\n",
            " Epoch: 140 loss: 0.051331\n",
            " Epoch: 141 loss: 0.051323\n",
            " Epoch: 142 loss: 0.051303\n",
            " Epoch: 143 loss: 0.051300\n",
            " Epoch: 144 loss: 0.051284\n",
            " Epoch: 145 loss: 0.051278\n",
            " Epoch: 146 loss: 0.051272\n",
            " Epoch: 147 loss: 0.051262\n",
            " Epoch: 148 loss: 0.051255\n",
            " Epoch: 149 loss: 0.051245\n",
            " Epoch: 150 loss: 0.051235\n",
            " Epoch: 151 loss: 0.051227\n",
            " Epoch: 152 loss: 0.051219\n",
            " Epoch: 153 loss: 0.051221\n",
            " Epoch: 154 loss: 0.051215\n",
            " Epoch: 155 loss: 0.051203\n",
            " Epoch: 156 loss: 0.051198\n",
            " Epoch: 157 loss: 0.051190\n",
            " Epoch: 158 loss: 0.051185\n",
            " Epoch: 159 loss: 0.051178\n",
            " Epoch: 160 loss: 0.051373\n",
            " Epoch: 161 loss: 0.037276\n",
            " Epoch: 162 loss: 0.051139\n",
            " Epoch: 163 loss: 0.051729\n",
            " Epoch: 164 loss: 0.051562\n",
            " Epoch: 165 loss: 0.051319\n",
            " Epoch: 166 loss: 0.051178\n",
            " Epoch: 167 loss: 0.051154\n",
            " Epoch: 168 loss: 0.051158\n",
            " Epoch: 169 loss: 0.051161\n",
            " Epoch: 170 loss: 0.051154\n",
            " Epoch: 171 loss: 0.051144\n",
            " Epoch: 172 loss: 0.051137\n",
            " Epoch: 173 loss: 0.051130\n",
            " Epoch: 174 loss: 0.051125\n",
            " Epoch: 175 loss: 0.051120\n",
            " Epoch: 176 loss: 0.051115\n",
            " Epoch: 177 loss: 0.051111\n",
            " Epoch: 178 loss: 0.051108\n",
            " Epoch: 179 loss: 0.051109\n",
            " Epoch: 180 loss: 0.051106\n",
            " Epoch: 181 loss: 0.051095\n",
            " Epoch: 182 loss: 0.051108\n",
            " Epoch: 183 loss: 0.051108\n",
            " Epoch: 184 loss: 0.051100\n",
            " Epoch: 185 loss: 0.051100\n",
            " Epoch: 186 loss: 0.051098\n",
            " Epoch: 187 loss: 0.051096\n",
            " Epoch: 188 loss: 0.051093\n",
            " Epoch: 189 loss: 0.051089\n",
            " Epoch: 190 loss: 0.051086\n",
            " Epoch: 191 loss: 0.051088\n",
            " Epoch: 192 loss: 0.051078\n",
            " Epoch: 193 loss: 0.051090\n",
            " Epoch: 194 loss: 0.051088\n",
            " Epoch: 195 loss: 0.051082\n",
            " Epoch: 196 loss: 0.051078\n",
            " Epoch: 197 loss: 0.051075\n",
            " Epoch: 198 loss: 0.051077\n",
            " Epoch: 199 loss: 0.051072\n",
            " Epoch: 200 loss: 0.051105\n",
            " Epoch: 201 loss: 0.051207\n",
            " Epoch: 202 loss: 0.051193\n",
            " Epoch: 203 loss: 0.051157\n",
            " Epoch: 204 loss: 0.051124\n",
            " Epoch: 205 loss: 0.051108\n",
            " Epoch: 206 loss: 0.051105\n",
            " Epoch: 207 loss: 0.051102\n",
            " Epoch: 208 loss: 0.051095\n",
            " Epoch: 209 loss: 0.051093\n",
            " Epoch: 210 loss: 0.051087\n",
            " Epoch: 211 loss: 0.051079\n",
            " Epoch: 212 loss: 0.051074\n",
            " Epoch: 213 loss: 0.051070\n",
            " Epoch: 214 loss: 0.051070\n",
            " Epoch: 215 loss: 0.051062\n",
            " Epoch: 216 loss: 0.051072\n",
            " Epoch: 217 loss: 0.051068\n",
            " Epoch: 218 loss: 0.051059\n",
            " Epoch: 219 loss: 0.051057\n",
            " Epoch: 220 loss: 0.051063\n",
            " Epoch: 221 loss: 0.051060\n",
            " Epoch: 222 loss: 0.051056\n",
            " Epoch: 223 loss: 0.051052\n",
            " Epoch: 224 loss: 0.051052\n",
            " Epoch: 225 loss: 0.051051\n",
            " Epoch: 226 loss: 0.051043\n",
            " Epoch: 227 loss: 0.051054\n",
            " Epoch: 228 loss: 0.051053\n",
            " Epoch: 229 loss: 0.051049\n",
            " Epoch: 230 loss: 0.051047\n",
            " Epoch: 231 loss: 0.051046\n",
            " Epoch: 232 loss: 0.051044\n",
            " Epoch: 233 loss: 0.051043\n",
            " Epoch: 234 loss: 0.051041\n",
            " Epoch: 235 loss: 0.051039\n",
            " Epoch: 236 loss: 0.051038\n",
            " Epoch: 237 loss: 0.051041\n",
            " Epoch: 238 loss: 0.051034\n",
            " Epoch: 239 loss: 0.051045\n",
            " Epoch: 240 loss: 0.051043\n",
            " Epoch: 241 loss: 0.051039\n",
            " Epoch: 242 loss: 0.051037\n",
            " Epoch: 243 loss: 0.051037\n",
            " Epoch: 244 loss: 0.051037\n",
            " Epoch: 245 loss: 0.051036\n",
            " Epoch: 246 loss: 0.051035\n",
            " Epoch: 247 loss: 0.051034\n",
            " Epoch: 248 loss: 0.051033\n",
            " Epoch: 249 loss: 0.051029\n",
            " Epoch: 250 loss: 0.051026\n",
            " Epoch: 251 loss: 0.051044\n",
            " Epoch: 252 loss: 0.051046\n",
            " Epoch: 253 loss: 0.051040\n",
            " Epoch: 254 loss: 0.051035\n",
            " Epoch: 255 loss: 0.051032\n",
            " Epoch: 256 loss: 0.051039\n",
            " Epoch: 257 loss: 0.051037\n",
            " Epoch: 258 loss: 0.051034\n",
            " Epoch: 259 loss: 0.051031\n",
            " Epoch: 260 loss: 0.051030\n",
            " Epoch: 261 loss: 0.051030\n",
            " Epoch: 262 loss: 0.051023\n",
            " Epoch: 263 loss: 0.051034\n",
            " Epoch: 264 loss: 0.051034\n",
            " Epoch: 265 loss: 0.051030\n",
            " Epoch: 266 loss: 0.051028\n",
            " Epoch: 267 loss: 0.051027\n",
            " Epoch: 268 loss: 0.051026\n",
            " Epoch: 269 loss: 0.051025\n",
            " Epoch: 270 loss: 0.051024\n",
            " Epoch: 271 loss: 0.051024\n",
            " Epoch: 272 loss: 0.051023\n",
            " Epoch: 273 loss: 0.051025\n",
            " Epoch: 274 loss: 0.051022\n",
            " Epoch: 275 loss: 0.051032\n",
            " Epoch: 276 loss: 0.051043\n",
            " Epoch: 277 loss: 0.051064\n",
            " Epoch: 278 loss: 0.051060\n",
            " Epoch: 279 loss: 0.051044\n",
            " Epoch: 280 loss: 0.051035\n",
            " Epoch: 281 loss: 0.051031\n",
            " Epoch: 282 loss: 0.051029\n",
            " Epoch: 283 loss: 0.051027\n",
            " Epoch: 284 loss: 0.051020\n",
            " Epoch: 285 loss: 0.051025\n",
            " Epoch: 286 loss: 0.051024\n",
            " Epoch: 287 loss: 0.051033\n",
            " Epoch: 288 loss: 0.051031\n",
            " Epoch: 289 loss: 0.051027\n",
            " Epoch: 290 loss: 0.051024\n",
            " Epoch: 291 loss: 0.051023\n",
            " Epoch: 292 loss: 0.051024\n",
            " Epoch: 293 loss: 0.051030\n",
            " Epoch: 294 loss: 0.051032\n",
            " Epoch: 295 loss: 0.051029\n",
            " Epoch: 296 loss: 0.051026\n",
            " Epoch: 297 loss: 0.051024\n",
            " Epoch: 298 loss: 0.051017\n",
            " Epoch: 299 loss: 0.051027\n",
            " Epoch: 300 loss: 0.051026\n",
            " Epoch: 301 loss: 0.051024\n",
            " Epoch: 302 loss: 0.051018\n",
            " Epoch: 303 loss: 0.051021\n",
            " Epoch: 304 loss: 0.051021\n",
            " Epoch: 305 loss: 0.051019\n",
            " Epoch: 306 loss: 0.051018\n",
            " Epoch: 307 loss: 0.051017\n",
            " Epoch: 308 loss: 0.051017\n",
            " Epoch: 309 loss: 0.051016\n",
            " Epoch: 310 loss: 0.051011\n",
            " Epoch: 311 loss: 0.051023\n",
            " Epoch: 312 loss: 0.051025\n",
            " Epoch: 313 loss: 0.051023\n",
            " Epoch: 314 loss: 0.051020\n",
            " Epoch: 315 loss: 0.051018\n",
            " Epoch: 316 loss: 0.051016\n",
            " Epoch: 317 loss: 0.051015\n",
            " Epoch: 318 loss: 0.051014\n",
            " Epoch: 319 loss: 0.051014\n",
            " Epoch: 320 loss: 0.051013\n",
            " Epoch: 321 loss: 0.051012\n",
            " Epoch: 322 loss: 0.051009\n",
            " Epoch: 323 loss: 0.051019\n",
            " Epoch: 324 loss: 0.051019\n",
            " Epoch: 325 loss: 0.051016\n",
            " Epoch: 326 loss: 0.051013\n",
            " Epoch: 327 loss: 0.051009\n",
            " Epoch: 328 loss: 0.051009\n",
            " Epoch: 329 loss: 0.051011\n",
            " Epoch: 330 loss: 0.051011\n",
            " Epoch: 331 loss: 0.051009\n",
            " Epoch: 332 loss: 0.051009\n",
            " Epoch: 333 loss: 0.051008\n",
            " Epoch: 334 loss: 0.051004\n",
            " Epoch: 335 loss: 0.051013\n",
            " Epoch: 336 loss: 0.051012\n",
            " Epoch: 337 loss: 0.051010\n",
            " Epoch: 338 loss: 0.051008\n",
            " Epoch: 339 loss: 0.051006\n",
            " Epoch: 340 loss: 0.051005\n",
            " Epoch: 341 loss: 0.051002\n",
            " Epoch: 342 loss: 0.050998\n",
            " Epoch: 343 loss: 0.051006\n",
            " Epoch: 344 loss: 0.051006\n",
            " Epoch: 345 loss: 0.051004\n",
            " Epoch: 346 loss: 0.050999\n",
            " Epoch: 347 loss: 0.050996\n",
            " Epoch: 348 loss: 0.051006\n",
            " Epoch: 349 loss: 0.051014\n",
            " Epoch: 350 loss: 0.051016\n",
            " Epoch: 351 loss: 0.051011\n",
            " Epoch: 352 loss: 0.051007\n",
            " Epoch: 353 loss: 0.051004\n",
            " Epoch: 354 loss: 0.051002\n",
            " Epoch: 355 loss: 0.051001\n",
            " Epoch: 356 loss: 0.051002\n",
            " Epoch: 357 loss: 0.051003\n",
            " Epoch: 358 loss: 0.051007\n",
            " Epoch: 359 loss: 0.051005\n",
            " Epoch: 360 loss: 0.051004\n",
            " Epoch: 361 loss: 0.050996\n",
            " Epoch: 362 loss: 0.051003\n",
            " Epoch: 363 loss: 0.051003\n",
            " Epoch: 364 loss: 0.051000\n",
            " Epoch: 365 loss: 0.050998\n",
            " Epoch: 366 loss: 0.050996\n",
            " Epoch: 367 loss: 0.050995\n",
            " Epoch: 368 loss: 0.050994\n",
            " Epoch: 369 loss: 0.050993\n",
            " Epoch: 370 loss: 0.050993\n",
            " Epoch: 371 loss: 0.050994\n",
            " Epoch: 372 loss: 0.050995\n",
            " Epoch: 373 loss: 0.050995\n",
            " Epoch: 374 loss: 0.050988\n",
            " Epoch: 375 loss: 0.050976\n",
            " Epoch: 376 loss: 0.050833\n",
            " Epoch: 377 loss: 0.050816\n",
            " Epoch: 378 loss: 0.050837\n",
            " Epoch: 379 loss: 0.050832\n",
            " Epoch: 380 loss: 0.050834\n",
            " Epoch: 381 loss: 0.050851\n",
            " Epoch: 382 loss: 0.050896\n",
            " Epoch: 383 loss: 0.050846\n",
            " Epoch: 384 loss: 0.050840\n",
            " Epoch: 385 loss: 0.050838\n",
            " Epoch: 386 loss: 0.050838\n",
            " Epoch: 387 loss: 0.050839\n",
            " Epoch: 388 loss: 0.050840\n",
            " Epoch: 389 loss: 0.050835\n",
            " Epoch: 390 loss: 0.050845\n",
            " Epoch: 391 loss: 0.050848\n",
            " Epoch: 392 loss: 0.050850\n",
            " Epoch: 393 loss: 0.050849\n",
            " Epoch: 394 loss: 0.050849\n",
            " Epoch: 395 loss: 0.050848\n",
            " Epoch: 396 loss: 0.050848\n",
            " Epoch: 397 loss: 0.050852\n",
            " Epoch: 398 loss: 0.050860\n",
            " Epoch: 399 loss: 0.050858\n",
            " Epoch: 400 loss: 0.050855\n",
            " Epoch: 401 loss: 0.050849\n",
            " Epoch: 402 loss: 0.050857\n",
            " Epoch: 403 loss: 0.050858\n",
            " Epoch: 404 loss: 0.050858\n",
            " Epoch: 405 loss: 0.050857\n",
            " Epoch: 406 loss: 0.050857\n",
            " Epoch: 407 loss: 0.050857\n",
            " Epoch: 408 loss: 0.050857\n",
            " Epoch: 409 loss: 0.050857\n",
            " Epoch: 410 loss: 0.050861\n",
            " Epoch: 411 loss: 0.051006\n",
            " Epoch: 412 loss: 0.050870\n",
            " Epoch: 413 loss: 0.050855\n",
            " Epoch: 414 loss: 0.050861\n",
            " Epoch: 415 loss: 0.050863\n",
            " Epoch: 416 loss: 0.050866\n",
            " Epoch: 417 loss: 0.050867\n",
            " Epoch: 418 loss: 0.066601\n",
            " Epoch: 419 loss: 0.050872\n",
            " Epoch: 420 loss: 0.052308\n",
            " Epoch: 421 loss: 0.051992\n",
            " Epoch: 422 loss: 0.051395\n",
            " Epoch: 423 loss: 0.051078\n",
            " Epoch: 424 loss: 0.050977\n",
            " Epoch: 425 loss: 0.050924\n",
            " Epoch: 426 loss: 0.050899\n",
            " Epoch: 427 loss: 0.050889\n",
            " Epoch: 428 loss: 0.050885\n",
            " Epoch: 429 loss: 0.050882\n",
            " Epoch: 430 loss: 0.050879\n",
            " Epoch: 431 loss: 0.050877\n",
            " Epoch: 432 loss: 0.050875\n",
            " Epoch: 433 loss: 0.050873\n",
            " Epoch: 434 loss: 0.050872\n",
            " Epoch: 435 loss: 0.050871\n",
            " Epoch: 436 loss: 0.050866\n",
            " Epoch: 437 loss: 0.050867\n",
            " Epoch: 438 loss: 0.050870\n",
            " Epoch: 439 loss: 0.050876\n",
            " Epoch: 440 loss: 0.050875\n",
            " Epoch: 441 loss: 0.050874\n",
            " Epoch: 442 loss: 0.050872\n",
            " Epoch: 443 loss: 0.050871\n",
            " Epoch: 444 loss: 0.050870\n",
            " Epoch: 445 loss: 0.050870\n",
            " Epoch: 446 loss: 0.050870\n",
            " Epoch: 447 loss: 0.050869\n",
            " Epoch: 448 loss: 0.050869\n",
            " Epoch: 449 loss: 0.050869\n",
            " Epoch: 450 loss: 0.050870\n",
            " Epoch: 451 loss: 0.050865\n",
            " Epoch: 452 loss: 0.050871\n",
            " Epoch: 453 loss: 0.050872\n",
            " Epoch: 454 loss: 0.050868\n",
            " Epoch: 455 loss: 0.050874\n",
            " Epoch: 456 loss: 0.050875\n",
            " Epoch: 457 loss: 0.050876\n",
            " Epoch: 458 loss: 0.050875\n",
            " Epoch: 459 loss: 0.050874\n",
            " Epoch: 460 loss: 0.050874\n",
            " Epoch: 461 loss: 0.050873\n",
            " Epoch: 462 loss: 0.050873\n",
            " Epoch: 463 loss: 0.050872\n",
            " Epoch: 464 loss: 0.050869\n",
            " Epoch: 465 loss: 0.050874\n",
            " Epoch: 466 loss: 0.050875\n",
            " Epoch: 467 loss: 0.050875\n",
            " Epoch: 468 loss: 0.050874\n",
            " Epoch: 469 loss: 0.050873\n",
            " Epoch: 470 loss: 0.050873\n",
            " Epoch: 471 loss: 0.050873\n",
            " Epoch: 472 loss: 0.050872\n",
            " Epoch: 473 loss: 0.050872\n",
            " Epoch: 474 loss: 0.050872\n",
            " Epoch: 475 loss: 0.050872\n",
            " Epoch: 476 loss: 0.050872\n",
            " Epoch: 477 loss: 0.050869\n",
            " Epoch: 478 loss: 0.050868\n",
            " Epoch: 479 loss: 0.050874\n",
            " Epoch: 480 loss: 0.050874\n",
            " Epoch: 481 loss: 0.050874\n",
            " Epoch: 482 loss: 0.050873\n",
            " Epoch: 483 loss: 0.050874\n",
            " Epoch: 484 loss: 0.050885\n",
            " Epoch: 485 loss: 0.050973\n",
            " Epoch: 486 loss: 0.050875\n",
            " Epoch: 487 loss: 0.050870\n",
            " Epoch: 488 loss: 0.050870\n",
            " Epoch: 489 loss: 0.050872\n",
            " Epoch: 490 loss: 0.050871\n",
            " Epoch: 491 loss: 0.050873\n",
            " Epoch: 492 loss: 0.050869\n",
            " Epoch: 493 loss: 0.050874\n",
            " Epoch: 494 loss: 0.050875\n",
            " Epoch: 495 loss: 0.050874\n",
            " Epoch: 496 loss: 0.050873\n",
            " Epoch: 497 loss: 0.050872\n",
            " Epoch: 498 loss: 0.050872\n",
            " Epoch: 499 loss: 0.050871\n",
            " Epoch: 500 loss: 0.050871\n",
            " Epoch: 501 loss: 0.050871\n",
            " Epoch: 502 loss: 0.050870\n",
            " Epoch: 503 loss: 0.050870\n",
            " Epoch: 504 loss: 0.050870\n",
            " Epoch: 505 loss: 0.050866\n",
            " Epoch: 506 loss: 0.050871\n",
            " Epoch: 507 loss: 0.050872\n",
            " Epoch: 508 loss: 0.050871\n",
            " Epoch: 509 loss: 0.050870\n",
            " Epoch: 510 loss: 0.050869\n",
            " Epoch: 511 loss: 0.050869\n",
            " Epoch: 512 loss: 0.050868\n",
            " Epoch: 513 loss: 0.050868\n",
            " Epoch: 514 loss: 0.050867\n",
            " Epoch: 515 loss: 0.050864\n",
            " Epoch: 516 loss: 0.050867\n",
            " Epoch: 517 loss: 0.050868\n",
            " Epoch: 518 loss: 0.050863\n",
            " Epoch: 519 loss: 0.050868\n",
            " Epoch: 520 loss: 0.050868\n",
            " Epoch: 521 loss: 0.050867\n",
            " Epoch: 522 loss: 0.050867\n",
            " Epoch: 523 loss: 0.051017\n",
            " Epoch: 524 loss: 0.051829\n",
            " Epoch: 525 loss: 0.088730\n",
            " Epoch: 526 loss: 0.074207\n",
            " Epoch: 527 loss: 0.071650\n",
            " Epoch: 528 loss: 0.090662\n",
            " Epoch: 529 loss: 0.257067\n",
            " Epoch: 530 loss: 0.450632\n",
            " Epoch: 531 loss: 0.151176\n",
            " Epoch: 532 loss: 0.123348\n",
            " Epoch: 533 loss: 0.136318\n",
            " Epoch: 534 loss: 0.097815\n",
            " Epoch: 535 loss: 0.061154\n",
            " Epoch: 536 loss: 0.057622\n",
            " Epoch: 537 loss: 0.055632\n",
            " Epoch: 538 loss: 0.058948\n",
            " Epoch: 539 loss: 0.054944\n",
            " Epoch: 540 loss: 0.054695\n",
            " Epoch: 541 loss: 0.054165\n",
            " Epoch: 542 loss: 0.053821\n",
            " Epoch: 543 loss: 0.053609\n",
            " Epoch: 544 loss: 0.053478\n",
            " Epoch: 545 loss: 0.053386\n",
            " Epoch: 546 loss: 0.053306\n",
            " Epoch: 547 loss: 0.053229\n",
            " Epoch: 548 loss: 0.053156\n",
            " Epoch: 549 loss: 0.053977\n",
            " Epoch: 550 loss: 0.052940\n",
            " Epoch: 551 loss: 0.053012\n",
            " Epoch: 552 loss: 0.052971\n",
            " Epoch: 553 loss: 0.052845\n",
            " Epoch: 554 loss: 0.052730\n",
            " Epoch: 555 loss: 0.052708\n",
            " Epoch: 556 loss: 0.052496\n",
            " Epoch: 557 loss: 0.052705\n",
            " Epoch: 558 loss: 0.052405\n",
            " Epoch: 559 loss: 0.052346\n",
            " Epoch: 560 loss: 0.052213\n",
            " Epoch: 561 loss: 0.052236\n",
            " Epoch: 562 loss: 0.052094\n",
            " Epoch: 563 loss: 0.052026\n",
            " Epoch: 564 loss: 0.052170\n",
            " Epoch: 565 loss: 0.051949\n",
            " Epoch: 566 loss: 0.051971\n",
            " Epoch: 567 loss: 0.051869\n",
            " Epoch: 568 loss: 0.051853\n",
            " Epoch: 569 loss: 0.051837\n",
            " Epoch: 570 loss: 0.051963\n",
            " Epoch: 571 loss: 0.051789\n",
            " Epoch: 572 loss: 0.051862\n",
            " Epoch: 573 loss: 0.051745\n",
            " Epoch: 574 loss: 0.051809\n",
            " Epoch: 575 loss: 0.051717\n",
            " Epoch: 576 loss: 0.051710\n",
            " Epoch: 577 loss: 0.051716\n",
            " Epoch: 578 loss: 0.051788\n",
            " Epoch: 579 loss: 0.051668\n",
            " Epoch: 580 loss: 0.051649\n",
            " Epoch: 581 loss: 0.051768\n",
            " Epoch: 582 loss: 0.051624\n",
            " Epoch: 583 loss: 0.051598\n",
            " Epoch: 584 loss: 0.051598\n",
            " Epoch: 585 loss: 0.051653\n",
            " Epoch: 586 loss: 0.051594\n",
            " Epoch: 587 loss: 0.051669\n",
            " Epoch: 588 loss: 0.051565\n",
            " Epoch: 589 loss: 0.051640\n",
            " Epoch: 590 loss: 0.051538\n",
            " Epoch: 591 loss: 0.051518\n",
            " Epoch: 592 loss: 0.051523\n",
            " Epoch: 593 loss: 0.051524\n",
            " Epoch: 594 loss: 0.051648\n",
            " Epoch: 595 loss: 0.051498\n",
            " Epoch: 596 loss: 0.051465\n",
            " Epoch: 597 loss: 0.051474\n",
            " Epoch: 598 loss: 0.051577\n",
            " Epoch: 599 loss: 0.051472\n",
            " Epoch: 600 loss: 0.051479\n",
            " Epoch: 601 loss: 0.051504\n",
            " Epoch: 602 loss: 0.051411\n",
            " Epoch: 603 loss: 0.051390\n",
            " Epoch: 604 loss: 0.051391\n",
            " Epoch: 605 loss: 0.051397\n",
            " Epoch: 606 loss: 0.051392\n",
            " Epoch: 607 loss: 0.051380\n",
            " Epoch: 608 loss: 0.051370\n",
            " Epoch: 609 loss: 0.051361\n",
            " Epoch: 610 loss: 0.051354\n",
            " Epoch: 611 loss: 0.051347\n",
            " Epoch: 612 loss: 0.051341\n",
            " Epoch: 613 loss: 0.051334\n",
            " Epoch: 614 loss: 0.051328\n",
            " Epoch: 615 loss: 0.051322\n",
            " Epoch: 616 loss: 0.051315\n",
            " Epoch: 617 loss: 0.051309\n",
            " Epoch: 618 loss: 0.051398\n",
            " Epoch: 619 loss: 0.051291\n",
            " Epoch: 620 loss: 0.051249\n",
            " Epoch: 621 loss: 0.051254\n",
            " Epoch: 622 loss: 0.051386\n",
            " Epoch: 623 loss: 0.051247\n",
            " Epoch: 624 loss: 0.051217\n",
            " Epoch: 625 loss: 0.051227\n",
            " Epoch: 626 loss: 0.051235\n",
            " Epoch: 627 loss: 0.051235\n",
            " Epoch: 628 loss: 0.051230\n",
            " Epoch: 629 loss: 0.051224\n",
            " Epoch: 630 loss: 0.051219\n",
            " Epoch: 631 loss: 0.051214\n",
            " Epoch: 632 loss: 0.051209\n",
            " Epoch: 633 loss: 0.051204\n",
            " Epoch: 634 loss: 0.051200\n",
            " Epoch: 635 loss: 0.051195\n",
            " Epoch: 636 loss: 0.051191\n",
            " Epoch: 637 loss: 0.051186\n",
            " Epoch: 638 loss: 0.051182\n",
            " Epoch: 639 loss: 0.051177\n",
            " Epoch: 640 loss: 0.051173\n",
            " Epoch: 641 loss: 0.051168\n",
            " Epoch: 642 loss: 0.051164\n",
            " Epoch: 643 loss: 0.051160\n",
            " Epoch: 644 loss: 0.051156\n",
            " Epoch: 645 loss: 0.051151\n",
            " Epoch: 646 loss: 0.051147\n",
            " Epoch: 647 loss: 0.051143\n",
            " Epoch: 648 loss: 0.051139\n",
            " Epoch: 649 loss: 0.051135\n",
            " Epoch: 650 loss: 0.051131\n",
            " Epoch: 651 loss: 0.051127\n",
            " Epoch: 652 loss: 0.051123\n",
            " Epoch: 653 loss: 0.051120\n",
            " Epoch: 654 loss: 0.051116\n",
            " Epoch: 655 loss: 0.051112\n",
            " Epoch: 656 loss: 0.051109\n",
            " Epoch: 657 loss: 0.051105\n",
            " Epoch: 658 loss: 0.051101\n",
            " Epoch: 659 loss: 0.051098\n",
            " Epoch: 660 loss: 0.051094\n",
            " Epoch: 661 loss: 0.051091\n",
            " Epoch: 662 loss: 0.051087\n",
            " Epoch: 663 loss: 0.051084\n",
            " Epoch: 664 loss: 0.051087\n",
            " Epoch: 665 loss: 0.051078\n",
            " Epoch: 666 loss: 0.051069\n",
            " Epoch: 667 loss: 0.051067\n",
            " Epoch: 668 loss: 0.051066\n",
            " Epoch: 669 loss: 0.051065\n",
            " Epoch: 670 loss: 0.051062\n",
            " Epoch: 671 loss: 0.051065\n",
            " Epoch: 672 loss: 0.051056\n",
            " Epoch: 673 loss: 0.051047\n",
            " Epoch: 674 loss: 0.051045\n",
            " Epoch: 675 loss: 0.051045\n",
            " Epoch: 676 loss: 0.051050\n",
            " Epoch: 677 loss: 0.051040\n",
            " Epoch: 678 loss: 0.051031\n",
            " Epoch: 679 loss: 0.051045\n",
            " Epoch: 680 loss: 0.051036\n",
            " Epoch: 681 loss: 0.051027\n",
            " Epoch: 682 loss: 0.051024\n",
            " Epoch: 683 loss: 0.051030\n",
            " Epoch: 684 loss: 0.051023\n",
            " Epoch: 685 loss: 0.051015\n",
            " Epoch: 686 loss: 0.051014\n",
            " Epoch: 687 loss: 0.051020\n",
            " Epoch: 688 loss: 0.051013\n",
            " Epoch: 689 loss: 0.051005\n",
            " Epoch: 690 loss: 0.051004\n",
            " Epoch: 691 loss: 0.051010\n",
            " Epoch: 692 loss: 0.051002\n",
            " Epoch: 693 loss: 0.051002\n",
            " Epoch: 694 loss: 0.051000\n",
            " Epoch: 695 loss: 0.050994\n",
            " Epoch: 696 loss: 0.050998\n",
            " Epoch: 697 loss: 0.050992\n",
            " Epoch: 698 loss: 0.050985\n",
            " Epoch: 699 loss: 0.050984\n",
            " Epoch: 700 loss: 0.050991\n",
            " Epoch: 701 loss: 0.050984\n",
            " Epoch: 702 loss: 0.050976\n",
            " Epoch: 703 loss: 0.050981\n",
            " Epoch: 704 loss: 0.050977\n",
            " Epoch: 705 loss: 0.050970\n",
            " Epoch: 706 loss: 0.050975\n",
            " Epoch: 707 loss: 0.050969\n",
            " Epoch: 708 loss: 0.050970\n",
            " Epoch: 709 loss: 0.050969\n",
            " Epoch: 710 loss: 0.050963\n",
            " Epoch: 711 loss: 0.050969\n",
            " Epoch: 712 loss: 0.050962\n",
            " Epoch: 713 loss: 0.050955\n",
            " Epoch: 714 loss: 0.051033\n",
            " Epoch: 715 loss: 0.050952\n",
            " Epoch: 716 loss: 0.050928\n",
            " Epoch: 717 loss: 0.050943\n",
            " Epoch: 718 loss: 0.050942\n",
            " Epoch: 719 loss: 0.050947\n",
            " Epoch: 720 loss: 0.050944\n",
            " Epoch: 721 loss: 0.050937\n",
            " Epoch: 722 loss: 0.050947\n",
            " Epoch: 723 loss: 0.050940\n",
            " Epoch: 724 loss: 0.050941\n",
            " Epoch: 725 loss: 0.050934\n",
            " Epoch: 726 loss: 0.050939\n",
            " Epoch: 727 loss: 0.050944\n",
            " Epoch: 728 loss: 0.050933\n",
            " Epoch: 729 loss: 0.050926\n",
            " Epoch: 730 loss: 0.050935\n",
            " Epoch: 731 loss: 0.050928\n",
            " Epoch: 732 loss: 0.050930\n",
            " Epoch: 733 loss: 0.050924\n",
            " Epoch: 734 loss: 0.050925\n",
            " Epoch: 735 loss: 0.050922\n",
            " Epoch: 736 loss: 0.050921\n",
            " Epoch: 737 loss: 0.050918\n",
            " Epoch: 738 loss: 0.050918\n",
            " Epoch: 739 loss: 0.050915\n",
            " Epoch: 740 loss: 0.050915\n",
            " Epoch: 741 loss: 0.050912\n",
            " Epoch: 742 loss: 0.050913\n",
            " Epoch: 743 loss: 0.050906\n",
            " Epoch: 744 loss: 0.050914\n",
            " Epoch: 745 loss: 0.050919\n",
            " Epoch: 746 loss: 0.050907\n",
            " Epoch: 747 loss: 0.050906\n",
            " Epoch: 748 loss: 0.050903\n",
            " Epoch: 749 loss: 0.050904\n",
            " Epoch: 750 loss: 0.050900\n",
            " Epoch: 751 loss: 0.050902\n",
            " Epoch: 752 loss: 0.050897\n",
            " Epoch: 753 loss: 0.050899\n",
            " Epoch: 754 loss: 0.050896\n",
            " Epoch: 755 loss: 0.050897\n",
            " Epoch: 756 loss: 0.050892\n",
            " Epoch: 757 loss: 0.050894\n",
            " Epoch: 758 loss: 0.050889\n",
            " Epoch: 759 loss: 0.050892\n",
            " Epoch: 760 loss: 0.050887\n",
            " Epoch: 761 loss: 0.050890\n",
            " Epoch: 762 loss: 0.050883\n",
            " Epoch: 763 loss: 0.050887\n",
            " Epoch: 764 loss: 0.050881\n",
            " Epoch: 765 loss: 0.050885\n",
            " Epoch: 766 loss: 0.050879\n",
            " Epoch: 767 loss: 0.050883\n",
            " Epoch: 768 loss: 0.050872\n",
            " Epoch: 769 loss: 0.050886\n",
            " Epoch: 770 loss: 0.050891\n",
            " Epoch: 771 loss: 0.050883\n",
            " Epoch: 772 loss: 0.050874\n",
            " Epoch: 773 loss: 0.050872\n",
            " Epoch: 774 loss: 0.050870\n",
            " Epoch: 775 loss: 0.050874\n",
            " Epoch: 776 loss: 0.050869\n",
            " Epoch: 777 loss: 0.050875\n",
            " Epoch: 778 loss: 0.050872\n",
            " Epoch: 779 loss: 0.050867\n",
            " Epoch: 780 loss: 0.050864\n",
            " Epoch: 781 loss: 0.050863\n",
            " Epoch: 782 loss: 0.050867\n",
            " Epoch: 783 loss: 0.050862\n",
            " Epoch: 784 loss: 0.050866\n",
            " Epoch: 785 loss: 0.050865\n",
            " Epoch: 786 loss: 0.050859\n",
            " Epoch: 787 loss: 0.050858\n",
            " Epoch: 788 loss: 0.050856\n",
            " Epoch: 789 loss: 0.050860\n",
            " Epoch: 790 loss: 0.050859\n",
            " Epoch: 791 loss: 0.050851\n",
            " Epoch: 792 loss: 0.050864\n",
            " Epoch: 793 loss: 0.050881\n",
            " Epoch: 794 loss: 0.050872\n",
            " Epoch: 795 loss: 0.050859\n",
            " Epoch: 796 loss: 0.050850\n",
            " Epoch: 797 loss: 0.050852\n",
            " Epoch: 798 loss: 0.050851\n",
            " Epoch: 799 loss: 0.050857\n",
            " Epoch: 800 loss: 0.050856\n",
            " Epoch: 801 loss: 0.050851\n",
            " Epoch: 802 loss: 0.050850\n",
            " Epoch: 803 loss: 0.050846\n",
            " Epoch: 804 loss: 0.050852\n",
            " Epoch: 805 loss: 0.050852\n",
            " Epoch: 806 loss: 0.050846\n",
            " Epoch: 807 loss: 0.050845\n",
            " Epoch: 808 loss: 0.050841\n",
            " Epoch: 809 loss: 0.050848\n",
            " Epoch: 810 loss: 0.050848\n",
            " Epoch: 811 loss: 0.050840\n",
            " Epoch: 812 loss: 0.050841\n",
            " Epoch: 813 loss: 0.050842\n",
            " Epoch: 814 loss: 0.050839\n",
            " Epoch: 815 loss: 0.050838\n",
            " Epoch: 816 loss: 0.050835\n",
            " Epoch: 817 loss: 0.050841\n",
            " Epoch: 818 loss: 0.050841\n",
            " Epoch: 819 loss: 0.050834\n",
            " Epoch: 820 loss: 0.050834\n",
            " Epoch: 821 loss: 0.050837\n",
            " Epoch: 822 loss: 0.050833\n",
            " Epoch: 823 loss: 0.050834\n",
            " Epoch: 824 loss: 0.050834\n",
            " Epoch: 825 loss: 0.050831\n",
            " Epoch: 826 loss: 0.050830\n",
            " Epoch: 827 loss: 0.050832\n",
            " Epoch: 828 loss: 0.050829\n",
            " Epoch: 829 loss: 0.050878\n",
            " Epoch: 830 loss: 0.050823\n",
            " Epoch: 831 loss: 0.050822\n",
            " Epoch: 832 loss: 0.050825\n",
            " Epoch: 833 loss: 0.050817\n",
            " Epoch: 834 loss: 0.050824\n",
            " Epoch: 835 loss: 0.050826\n",
            " Epoch: 836 loss: 0.050821\n",
            " Epoch: 837 loss: 0.050824\n",
            " Epoch: 838 loss: 0.050825\n",
            " Epoch: 839 loss: 0.050815\n",
            " Epoch: 840 loss: 0.050828\n",
            " Epoch: 841 loss: 0.050838\n",
            " Epoch: 842 loss: 0.050833\n",
            " Epoch: 843 loss: 0.050821\n",
            " Epoch: 844 loss: 0.050816\n",
            " Epoch: 845 loss: 0.050819\n",
            " Epoch: 846 loss: 0.050821\n",
            " Epoch: 847 loss: 0.050815\n",
            " Epoch: 848 loss: 0.050822\n",
            " Epoch: 849 loss: 0.050822\n",
            " Epoch: 850 loss: 0.050813\n",
            " Epoch: 851 loss: 0.050818\n",
            " Epoch: 852 loss: 0.050819\n",
            " Epoch: 853 loss: 0.050811\n",
            " Epoch: 854 loss: 0.050818\n",
            " Epoch: 855 loss: 0.050818\n",
            " Epoch: 856 loss: 0.050807\n",
            " Epoch: 857 loss: 0.050816\n",
            " Epoch: 858 loss: 0.050816\n",
            " Epoch: 859 loss: 0.050805\n",
            " Epoch: 860 loss: 0.050815\n",
            " Epoch: 861 loss: 0.050814\n",
            " Epoch: 862 loss: 0.050803\n",
            " Epoch: 863 loss: 0.050812\n",
            " Epoch: 864 loss: 0.050812\n",
            " Epoch: 865 loss: 0.050801\n",
            " Epoch: 866 loss: 0.050812\n",
            " Epoch: 867 loss: 0.050811\n",
            " Epoch: 868 loss: 0.050806\n",
            " Epoch: 869 loss: 0.050803\n",
            " Epoch: 870 loss: 0.050829\n",
            " Epoch: 871 loss: 0.050807\n",
            " Epoch: 872 loss: 0.050791\n",
            " Epoch: 873 loss: 0.050805\n",
            " Epoch: 874 loss: 0.050805\n",
            " Epoch: 875 loss: 0.050796\n",
            " Epoch: 876 loss: 0.050799\n",
            " Epoch: 877 loss: 0.050802\n",
            " Epoch: 878 loss: 0.050801\n",
            " Epoch: 879 loss: 0.050803\n",
            " Epoch: 880 loss: 0.050804\n",
            " Epoch: 881 loss: 0.050801\n",
            " Epoch: 882 loss: 0.050798\n",
            " Epoch: 883 loss: 0.050802\n",
            " Epoch: 884 loss: 0.050804\n",
            " Epoch: 885 loss: 0.050798\n",
            " Epoch: 886 loss: 0.050795\n",
            " Epoch: 887 loss: 0.050797\n",
            " Epoch: 888 loss: 0.050803\n",
            " Epoch: 889 loss: 0.050796\n",
            " Epoch: 890 loss: 0.050792\n",
            " Epoch: 891 loss: 0.050795\n",
            " Epoch: 892 loss: 0.050799\n",
            " Epoch: 893 loss: 0.050796\n",
            " Epoch: 894 loss: 0.050789\n",
            " Epoch: 895 loss: 0.050793\n",
            " Epoch: 896 loss: 0.050796\n",
            " Epoch: 897 loss: 0.050791\n",
            " Epoch: 898 loss: 0.050787\n",
            " Epoch: 899 loss: 0.050791\n",
            " Epoch: 900 loss: 0.050863\n",
            " Epoch: 901 loss: 0.050789\n",
            " Epoch: 902 loss: 0.050766\n",
            " Epoch: 903 loss: 0.050777\n",
            " Epoch: 904 loss: 0.050790\n",
            " Epoch: 905 loss: 0.050784\n",
            " Epoch: 906 loss: 0.050773\n",
            " Epoch: 907 loss: 0.050786\n",
            " Epoch: 908 loss: 0.050789\n",
            " Epoch: 909 loss: 0.050783\n",
            " Epoch: 910 loss: 0.050771\n",
            " Epoch: 911 loss: 0.050802\n",
            " Epoch: 912 loss: 0.050810\n",
            " Epoch: 913 loss: 0.050801\n",
            " Epoch: 914 loss: 0.050791\n",
            " Epoch: 915 loss: 0.050795\n",
            " Epoch: 916 loss: 0.050779\n",
            " Epoch: 917 loss: 0.050788\n",
            " Epoch: 918 loss: 0.050792\n",
            " Epoch: 919 loss: 0.050784\n",
            " Epoch: 920 loss: 0.050776\n",
            " Epoch: 921 loss: 0.050779\n",
            " Epoch: 922 loss: 0.050784\n",
            " Epoch: 923 loss: 0.050790\n",
            " Epoch: 924 loss: 0.050784\n",
            " Epoch: 925 loss: 0.050775\n",
            " Epoch: 926 loss: 0.050771\n",
            " Epoch: 927 loss: 0.050778\n",
            " Epoch: 928 loss: 0.050783\n",
            " Epoch: 929 loss: 0.050779\n",
            " Epoch: 930 loss: 0.050772\n",
            " Epoch: 931 loss: 0.050768\n",
            " Epoch: 932 loss: 0.050776\n",
            " Epoch: 933 loss: 0.050784\n",
            " Epoch: 934 loss: 0.050777\n",
            " Epoch: 935 loss: 0.050770\n",
            " Epoch: 936 loss: 0.050761\n",
            " Epoch: 937 loss: 0.050773\n",
            " Epoch: 938 loss: 0.050818\n",
            " Epoch: 939 loss: 0.050772\n",
            " Epoch: 940 loss: 0.050754\n",
            " Epoch: 941 loss: 0.050755\n",
            " Epoch: 942 loss: 0.050767\n",
            " Epoch: 943 loss: 0.050777\n",
            " Epoch: 944 loss: 0.050776\n",
            " Epoch: 945 loss: 0.050766\n",
            " Epoch: 946 loss: 0.050745\n",
            " Epoch: 947 loss: 0.050773\n",
            " Epoch: 948 loss: 0.050776\n",
            " Epoch: 949 loss: 0.050768\n",
            " Epoch: 950 loss: 0.050761\n",
            " Epoch: 951 loss: 0.050753\n",
            " Epoch: 952 loss: 0.051350\n",
            " Epoch: 953 loss: 0.050699\n",
            " Epoch: 954 loss: 0.050806\n",
            " Epoch: 955 loss: 0.050808\n",
            " Epoch: 956 loss: 0.050786\n",
            " Epoch: 957 loss: 0.050768\n",
            " Epoch: 958 loss: 0.050786\n",
            " Epoch: 959 loss: 0.050806\n",
            " Epoch: 960 loss: 0.050793\n",
            " Epoch: 961 loss: 0.050779\n",
            " Epoch: 962 loss: 0.050769\n",
            " Epoch: 963 loss: 0.050760\n",
            " Epoch: 964 loss: 0.050753\n",
            " Epoch: 965 loss: 0.050747\n",
            " Epoch: 966 loss: 0.050764\n",
            " Epoch: 967 loss: 0.050772\n",
            " Epoch: 968 loss: 0.050764\n",
            " Epoch: 969 loss: 0.050757\n",
            " Epoch: 970 loss: 0.050750\n",
            " Epoch: 971 loss: 0.050747\n",
            " Epoch: 972 loss: 0.050760\n",
            " Epoch: 973 loss: 0.050768\n",
            " Epoch: 974 loss: 0.050762\n",
            " Epoch: 975 loss: 0.050754\n",
            " Epoch: 976 loss: 0.050745\n",
            " Epoch: 977 loss: 0.050739\n",
            " Epoch: 978 loss: 0.050757\n",
            " Epoch: 979 loss: 0.050762\n",
            " Epoch: 980 loss: 0.050756\n",
            " Epoch: 981 loss: 0.050746\n",
            " Epoch: 982 loss: 0.050741\n",
            " Epoch: 983 loss: 0.050737\n",
            " Epoch: 984 loss: 0.050752\n",
            " Epoch: 985 loss: 0.050759\n",
            " Epoch: 986 loss: 0.050752\n",
            " Epoch: 987 loss: 0.050745\n",
            " Epoch: 988 loss: 0.050737\n",
            " Epoch: 989 loss: 0.050730\n",
            " Epoch: 990 loss: 0.050746\n",
            " Epoch: 991 loss: 0.050758\n",
            " Epoch: 992 loss: 0.050749\n",
            " Epoch: 993 loss: 0.050738\n",
            " Epoch: 994 loss: 0.050731\n",
            " Epoch: 995 loss: 0.050728\n",
            " Epoch: 996 loss: 0.050743\n",
            " Epoch: 997 loss: 0.050751\n",
            " Epoch: 998 loss: 0.050745\n",
            " Epoch: 999 loss: 0.050734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(X_test, Y_test, loss_fn):\n",
        "    size = len(X_test)\n",
        "    batch_size = 16\n",
        "    #epochs=1000\n",
        "    n_batches = int(size/batch_size)\n",
        "    for epoch_id in range(epochs):\n",
        "      running_loss = []\n",
        "      epoch_acc=[]\n",
        "      model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "     for batch_id in range(n_batches):\n",
        "          X_batch = X_test[batch_id*batch_size: (batch_id+1)*batch_size]\n",
        "          Y_batch = Y_test[batch_id*batch_size: (batch_id+1)*batch_size]\n",
        "          X_batch = np.array(X_batch)\n",
        "          Y_batch = np.array(Y_batch)\n",
        "          X_batch = torch.FloatTensor(X_batch)\n",
        "          Y_batch = torch.FloatTensor(Y_batch)\n",
        "\n",
        "\n",
        "          # Compute prediction and loss\n",
        "          pred = model(X_batch)\n",
        "          loss = loss_fn(pred, Y_batch)\n",
        "          acc = binary_acc(pred, Y_batch)\n",
        "          running_loss.append(loss.item())\n",
        "          epoch_acc.append(acc.item())\n",
        "          #optimizer.zero_grad()\n",
        "          #loss.backward()\n",
        "          #optimizer.step()\n",
        "          loss, current = loss.item(), batch_id * len(X)\n",
        "\n",
        "          \n",
        "          print(f\" bce_loss: {np.mean(running_loss):>7f}\")\n"
      ],
      "metadata": {
        "id": "oPTEtILukOMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(X_test, Y_test, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgjDYth5kOZL",
        "outputId": "5c44f897-e442-462e-c698-d95cf3a4cbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " bce_loss: 0.457306\n",
            " bce_loss: 1.726303\n",
            " bce_loss: 1.989224\n",
            " bce_loss: 1.897549\n",
            " bce_loss: 2.179004\n",
            " bce_loss: 1.884765\n",
            " bce_loss: 1.683480\n",
            " bce_loss: 1.589204\n"
          ]
        }
      ]
    }
  ]
}